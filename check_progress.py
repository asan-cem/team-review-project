import pandas as pd
import json
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def check_excel_data():
    """Excel íŒŒì¼ì˜ í˜„ì¬ ìƒíƒœ í™•ì¸"""
    print("=== ì›ë³¸ ë°ì´í„° ë¶„ì„ ===")
    
    # Excel íŒŒì¼ ì½ê¸°
    df = pd.read_excel('ì„¤ë¬¸ì¡°ì‚¬_ì „ì²˜ë¦¬ë°ì´í„°_20250620_0731.xlsx', engine='openpyxl')
    
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
    print(f"ğŸ“ 'í˜‘ì—… í›„ê¸°' ì»¬ëŸ¼ ë¹„ì–´ìˆì§€ ì•Šì€ ë°ì´í„°: {df['í˜‘ì—… í›„ê¸°'].notna().sum():,}ê±´")
    
    # í˜‘ì—… í›„ê¸° ë°ì´í„°ë§Œ ì¶”ì¶œ
    feedback_data = df['í˜‘ì—… í›„ê¸°'].dropna()
    
    print(f"\n=== í˜‘ì—… í›„ê¸° ë°ì´í„° ìƒ˜í”Œ (ì²« 5ê±´) ===")
    for i, text in enumerate(feedback_data.head(5), 1):
        print(f"{i}. {str(text)[:100]}...")
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬
    text_lengths = feedback_data.str.len()
    print(f"\n=== í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„ ===")
    print(f"í‰ê·  ê¸¸ì´: {text_lengths.mean():.1f}ì")
    print(f"ìµœì†Œ ê¸¸ì´: {text_lengths.min()}ì")
    print(f"ìµœëŒ€ ê¸¸ì´: {text_lengths.max()}ì")
    print(f"ì¤‘ê°„ê°’: {text_lengths.median():.1f}ì")
    
    # ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ (ê°„ë‹¨í•œ ë¶„ì„)
    all_text = ' '.join(feedback_data.astype(str))
    words = all_text.split()
    word_counts = Counter(words)
    
    print(f"\n=== ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ TOP 10 ===")
    for word, count in word_counts.most_common(10):
        print(f"{word}: {count}íšŒ")
    
    # ì²« 5000ê±´ í™•ì¸
    first_5000 = df.head(5000)
    first_5000_feedback = first_5000['í˜‘ì—… í›„ê¸°'].dropna()
    
    print(f"\n=== ì²« 5000ê±´ ì¤‘ í˜‘ì—… í›„ê¸° ë°ì´í„° ===")
    print(f"ì²« 5000ê±´ ì¤‘ í”¼ë“œë°±ì´ ìˆëŠ” ê±´ìˆ˜: {len(first_5000_feedback):,}ê±´")
    print(f"ë¹„ìœ¨: {len(first_5000_feedback)/5000*100:.1f}%")
    
    return df, feedback_data

def analyze_sample_patterns(feedback_data, sample_size=100):
    """ìƒ˜í”Œ ë°ì´í„°ì˜ íŒ¨í„´ ë¶„ì„"""
    print(f"\n=== ìƒ˜í”Œ {sample_size}ê±´ íŒ¨í„´ ë¶„ì„ ===")
    
    sample = feedback_data.head(sample_size)
    
    # ê°„ë‹¨í•œ ê°ì • ë¶„ë¥˜ (í‚¤ì›Œë“œ ê¸°ë°˜)
    positive_keywords = ['ê°ì‚¬', 'ë§Œì¡±', 'ì¢‹', 'í›Œë¥­', 'ì¹œì ˆ', 'ë¹ ë¥´', 'ë„ì›€']
    negative_keywords = ['ë¶ˆë§Œ', 'ì•„ì‰¬', 'ì–´ë ¤ì›€', 'ëŠ¦', 'ë¶ˆì¹œì ˆ', 'ë¬¸ì œ', 'ê°œì„ ']
    neutral_keywords = ['ì—†ìŒ', 'í•´ë‹¹ì—†ìŒ', 'ë¬´', 'íŠ¹ë³„íˆ']
    
    positive_count = 0
    negative_count = 0
    neutral_count = 0
    
    for text in sample:
        text_str = str(text).lower()
        
        if any(keyword in text_str for keyword in positive_keywords):
            positive_count += 1
        elif any(keyword in text_str for keyword in negative_keywords):
            negative_count += 1
        elif any(keyword in text_str for keyword in neutral_keywords):
            neutral_count += 1
        else:
            # ê¸¸ì´ë¡œ íŒë‹¨
            if len(text_str) < 10:
                neutral_count += 1
    
    print(f"ê¸ì •ì  í”¼ë“œë°± (ì¶”ì •): {positive_count}ê±´ ({positive_count/sample_size*100:.1f}%)")
    print(f"ë¶€ì •ì  í”¼ë“œë°± (ì¶”ì •): {negative_count}ê±´ ({negative_count/sample_size*100:.1f}%)")
    print(f"ì¤‘ë¦½ì  í”¼ë“œë°± (ì¶”ì •): {neutral_count}ê±´ ({neutral_count/sample_size*100:.1f}%)")
    print(f"ê¸°íƒ€: {sample_size - positive_count - negative_count - neutral_count}ê±´")

def check_medical_terms(feedback_data, sample_size=100):
    """ì˜ë£Œ ìš©ì–´ ì‚¬ìš© ë¹ˆë„ í™•ì¸"""
    print(f"\n=== ì˜ë£Œ ìš©ì–´ ì‚¬ìš© ë¹ˆë„ (ìƒ˜í”Œ {sample_size}ê±´) ===")
    
    medical_terms = [
        'ICU', 'ER', 'OR', 'CT', 'MRI', 'EMR', 'PACS', 'HIS', 'LIS',
        'ì‘ê¸‰ì‹¤', 'ì¤‘í™˜ìì‹¤', 'ìˆ˜ìˆ ì‹¤', 'ì™¸ë˜', 'ë³‘ë™', 'ê°„í˜¸ì‚¬', 'ì˜ì‚¬', 'ì•½ì‚¬',
        'ê²€ì‚¬', 'ì²˜ë°©', 'ì§„ë£Œ', 'ì…ì›', 'í‡´ì›', 'ìˆ˜ìˆ ', 'ë§ˆì·¨', 'íˆ¬ì•½',
        'í˜ˆì•¡', 'ë°©ì‚¬ì„ ', 'ë³‘ë¦¬', 'ì¬í™œ', 'ì •í˜•ì™¸ê³¼', 'ë‚´ê³¼', 'ì™¸ê³¼'
    ]
    
    sample = feedback_data.head(sample_size)
    term_counts = {}
    
    for term in medical_terms:
        count = sum(1 for text in sample if term in str(text))
        if count > 0:
            term_counts[term] = count
    
    # ë¹ˆë„ìˆœ ì •ë ¬
    sorted_terms = sorted(term_counts.items(), key=lambda x: x[1], reverse=True)
    
    print("ë°œê²¬ëœ ì˜ë£Œ ìš©ì–´:")
    for term, count in sorted_terms[:15]:  # ìƒìœ„ 15ê°œë§Œ í‘œì‹œ
        print(f"  {term}: {count}íšŒ ({count/sample_size*100:.1f}%)")

def main():
    print("ğŸ” í˜‘ì—… í›„ê¸° ë°ì´í„° í˜„í™© ë¶„ì„")
    print("=" * 50)
    
    try:
        # ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„
        df, feedback_data = check_excel_data()
        
        # íŒ¨í„´ ë¶„ì„
        analyze_sample_patterns(feedback_data, 200)
        
        # ì˜ë£Œ ìš©ì–´ ë¶„ì„
        check_medical_terms(feedback_data, 500)
        
        print(f"\n{'='*50}")
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("ğŸ’¡ AI ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì´ ë°ì´í„°ë“¤ì„ ë” ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•  ì˜ˆì •ì…ë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()