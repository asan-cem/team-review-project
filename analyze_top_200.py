import pandas as pd
import json
import time
from pathlib import Path
import vertexai
from vertexai.generative_models import GenerativeModel
import warnings
warnings.filterwarnings('ignore')

# ê³ ë„í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
ADVANCED_PROMPT_TEMPLATE = """
[í˜ë¥´ì†Œë‚˜]
ë‹¹ì‹ ì€ ì˜ë£Œê¸°ê´€ ë‚´ë¶€ ì§ì› ë§Œì¡±ë„ ë° í˜‘ì—… í”¼ë“œë°±ì„ ë¶„ì„í•˜ëŠ” ê³ ê¸‰ AI ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜ë£Œ ìš©ì–´, ì—…ë¬´ ìš©ì–´, ì•½ì–´ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

[ì§€ì‹œì‚¬í•­]
1. ì£¼ì–´ì§„ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì˜ë¯¸ë¥¼ ë³´ì¡´í•˜ë©´ì„œ, ì˜¤íƒ€ì™€ ë¬¸ë²•ì„ êµì •í•˜ì—¬ refined_textë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
2. ì†ê±°ë‚˜ ê³µê²©ì ì¸ í‘œí˜„ì€ ì „ë¬¸ì ì´ê³  ì •ì¤‘í•œ í‘œí˜„ìœ¼ë¡œ ìˆœí™”í•©ë‹ˆë‹¤.
3. **ë¹„ì‹ë³„ ì²˜ë¦¬ ê·œì¹™** (ë¶€ì •ì  í”¼ë“œë°±ì´ë©´ì„œ ì•„ë˜ ì¡°ê±´ì— í•´ë‹¹í•  ê²½ìš°ì—ë§Œ):
   - ì‹¤ëª…ì´ ëª…ì‹œëœ ê²½ìš° (ì˜ˆ: "ê¹€ë¯¼í¬ ì§ì›", "í˜ˆì•¡ì€í–‰ ê¹€í˜„ì„± ì§ì›")
   - ì†Œìˆ˜ ì¸ì›ìœ¼ë¡œ íŠ¹ì • ê°€ëŠ¥í•œ êµ¬ì²´ì  í˜¸ì¹­ (ì˜ˆ: "íŒ€ì¥", "ê³¼ì¥", "ëŒ€ë¦¬", "ì—¬ì ì§ì›")
   - ë¶€ì„œëª…+ì§ì±…ì´ ê²°í•©ëœ ê²½ìš° (ì˜ˆ: "í˜ˆì•¡ì€í–‰ ê¹€í˜„ì„±", "ë§ˆì¼€íŒ…íŒ€ ê³¼ì¥")
   **ì ˆëŒ€ ê·œì¹™**: ê¸ì •ì ì´ê±°ë‚˜ ì¤‘ë¦½ì  í”¼ë“œë°±ì€ ì–´ë–¤ ê²½ìš°ì—ë„ is_anonymizedë¥¼ falseë¡œ ì„¤ì •
4. "ì—†ìŒ" ë“± ë¬´ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ëŠ” refined_textë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

[ê°ì • ë¶„ì„ - 2ë‹¨ê³„ ë¶„ë¥˜]
**1ë‹¨ê³„ (ì£¼ê°ì •)**: "ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½" ì¤‘ í•˜ë‚˜
**2ë‹¨ê³„ (ì„¸ë¶€ê°ì •)**: ì£¼ê°ì •ì— ë”°ë¥¸ ì„¸ë¶€ ë¶„ë¥˜
- ê¸ì •: "ë§Œì¡±", "ê°ì‚¬", "ì¹­ì°¬", "ê²©ë ¤", "ê¸°ëŒ€"
- ë¶€ì •: "ë¶ˆë§Œ", "ì‹¤ë§", "ë¶„ë…¸", "ìš°ë ¤", "ë¹„íŒ"  
- ì¤‘ë¦½: "ì œì•ˆ", "ì •ë³´", "ì§ˆë¬¸", "ê´€ì°°", "ê¸°íƒ€"

[í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ]
í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì˜ë£Œ ìš©ì–´, ë¶€ì„œëª…, ì—…ë¬´ ê´€ë ¨ ìš©ì–´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨í•˜ì„¸ìš”.

[ë¶„ë¥˜ ì²´ê³„]
ë‹¤ìŒ ì¤‘ í•´ë‹¹í•˜ëŠ” ëª¨ë“  ë¼ë²¨ì„ í¬í•¨:
- "ë¶€ì„œê°„ í˜‘ì—…": ì„œë¡œ ë‹¤ë¥¸ ë¶€ì„œ/íŒ€ ê°„ì˜ ì—…ë¬´ ì—°ê³„ì™€ í˜‘ë ¥ ë¬¸ì œ
- "ì§ì›ê°„ ì†Œí†µ": ê°™ì€ ë¶€ì„œ/íŒ€ ë‚´ ë™ë£Œ ê°„ì˜ ì†Œí†µ ë° ê´€ê³„ ë¬¸ì œ  
- "ì „ë¬¸ì„± ë¶€ì¡±": ê°œì¸ì˜ ì—…ë¬´ ì§€ì‹, ê¸°ìˆ , ê²½í—˜ ë¶€ì¡± ë¬¸ì œ
- "ì—…ë¬´ íƒœë„": ì±…ì„ê°, ì ê·¹ì„± ë“± ì—…ë¬´ë¥¼ ëŒ€í•˜ëŠ” ìì„¸ ë¬¸ì œ
- "ìƒí˜¸ ì¡´ì¤‘": ì¸ê²©ì  ëŒ€ìš°, ë°°ë ¤ ë“± ê´€ê³„ì—ì„œì˜ ì˜ˆì˜ ë¬¸ì œ
- "ì‹œìŠ¤í…œ/í”„ë¡œì„¸ìŠ¤": ì—…ë¬´ ì‹œìŠ¤í…œ, ì ˆì°¨, í™˜ê²½ ê´€ë ¨ ë¬¸ì œ
- "êµìœ¡/í›ˆë ¨": ì§ì› êµìœ¡, ì—­ëŸ‰ ê°œë°œ ê´€ë ¨ ì‚¬í•­
- "ë¦¬ë”ì‹­": ê´€ë¦¬ì, íŒ€ì¥ ë“±ì˜ ë¦¬ë”ì‹­ ê´€ë ¨ ì‚¬í•­

[ì¶œë ¥ í˜•ì‹]
{{
  "refined_text": "ì •ì œëœ í…ìŠ¤íŠ¸",
  "is_anonymized": false,
  "primary_sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "detailed_sentiment": "ì„¸ë¶€ê°ì •",
  "sentiment_intensity": ê°ì •ê°•ë„ì ìˆ˜(1-10),
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
  "labels": ["ë¼ë²¨1", "ë¼ë²¨2"],
}}

ì°¸ê³ : ê°ì •ê°•ë„ëŠ” ë‹¤ìŒ ì„¸ë¶€ ê¸°ì¤€ì„ ë”°ë¦„
1-2: ë§¤ìš° ì•½í•œ ê°ì • (ë¯¸ë¯¸í•œ ê¸ì •/ë¶€ì •, í˜•ì‹ì  í‘œí˜„)
3-4: ì•½í•œ ê°ì • (ì‚´ì§ ê¸ì •/ë¶€ì •, ì¼ë°˜ì ì¸ ë§Œì¡±/ë¶ˆë§Œì¡±)
5-6: ë³´í†µ ê°ì • (ë¶„ëª…í•œ ê°ì • í‘œí˜„, êµ¬ì²´ì  ì´ìœ  ìˆìŒ)
7-8: ê°•í•œ ê°ì • (ë§¤ìš° ê¸ì •/ë¶€ì •, ê°•ì¡° í‘œí˜„ í¬í•¨)
9-10: ê·¹ë„ë¡œ ê°•í•œ ê°ì • (ê·¹ì°¬/ê·¹ë„ ë¶ˆë§Œ, ê°ì •ì  í‘œí˜„ í’ë¶€)

ì›ë³¸ í…ìŠ¤íŠ¸: "{original_text}"
"""

class Top200Analyzer:
    def __init__(self, project_id: str, location: str = "us-central1"):
        """ìƒìœ„ 200ê±´ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        vertexai.init(project=project_id, location=location)
        self.model = GenerativeModel("gemini-2.0-flash")
        
    
    
    def analyze_review(self, original_text: str) -> dict:
        """ë‹¨ì¼ ë¦¬ë·° ë¶„ì„"""
        if not original_text or str(original_text).strip() == "":
            return {
                "refined_text": "",
                "is_anonymized": False,
                "primary_sentiment": "ì¤‘ë¦½",
                "detailed_sentiment": "ê¸°íƒ€",
                "sentiment_intensity": 5,
                "keywords": [],
                "labels": []
            }
        
        # ì „ì²˜ë¦¬
        processed_text = str(original_text).strip()
        
        prompt = ADVANCED_PROMPT_TEMPLATE.format(original_text=processed_text)
        
        try:
            print(f"    ğŸ¤– AI ë¶„ì„ ì¤‘: {processed_text[:30]}...")
            response = self.model.generate_content(prompt)
            response_text = response.text.strip()
            
            # JSON íŒŒì‹±
            try:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_text = response_text[json_start:json_end]
                    result = json.loads(json_text)
                    
                    # ê²°ê³¼ ê°„ë‹¨ í‘œì‹œ
                    sentiment = result.get('primary_sentiment', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    detailed = result.get('detailed_sentiment', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    print(f"    âœ… ì™„ë£Œ: {sentiment} ({detailed})")
                    
                    return result
                else:
                    raise json.JSONDecodeError("No JSON found", response_text, 0)
                    
            except json.JSONDecodeError:
                print(f"    âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
                return self._create_fallback_result(processed_text)
                
        except Exception as e:
            print(f"    âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._create_fallback_result(processed_text)
    
    def _create_fallback_result(self, processed_text: str) -> dict:
        """API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±"""
        return {
            "refined_text": processed_text,
            "is_anonymized": False,
            "primary_sentiment": "ì¤‘ë¦½",
            "detailed_sentiment": "ê¸°íƒ€",
            "sentiment_intensity": 5,
            "keywords": [],
            "labels": []
        }

def main():
    print("ğŸ” í˜‘ì—… í›„ê¸° ìƒìœ„ 200ê±´ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    try:
        # 1. ì›ë³¸ Excel íŒŒì¼ ì½ê¸°
        print("ğŸ“ ì›ë³¸ íŒŒì¼ ë¡œë”©...")
        df = pd.read_excel('ì„¤ë¬¸ì¡°ì‚¬_ì „ì²˜ë¦¬ë°ì´í„°_20250620_0731.xlsx', engine='openpyxl')
        
        # 2. í˜‘ì—… í›„ê¸°ê°€ ìˆëŠ” ìƒìœ„ 200ê±´ ì¶”ì¶œ
        print("ğŸ“Š í˜‘ì—… í›„ê¸° ë°ì´í„° ì¶”ì¶œ...")
        feedback_df = df[df['í˜‘ì—… í›„ê¸°'].notna()].head(200).copy()
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(feedback_df)}ê±´")
        
        # 3. AI ë¶„ì„ ì‹œì‘
        print(f"\nğŸ¤– AI ë¶„ì„ ì‹œì‘ (ì´ {len(feedback_df)}ê±´)")
        analyzer = Top200Analyzer(project_id="mindmap-462708")
        
        results = []
        for i, (idx, row) in enumerate(feedback_df.iterrows(), 1):
            print(f"\n[{i}/{len(feedback_df)}] ë¶„ì„ ì¤‘...")
            original_text = str(row['í˜‘ì—… í›„ê¸°'])
            
            result = analyzer.analyze_review(original_text)
            results.append(result)
            
            # API í˜¸ì¶œ ì œí•œ
            time.sleep(0.1)
        
        # 4. ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ì¶”ê°€
        print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼ë¥¼ ì›ë³¸ ì‹œíŠ¸ì— ì¶”ê°€...")
        
        # ë¶„ì„ ê²°ê³¼ ì»¬ëŸ¼ë“¤ ì¶”ê°€
        feedback_df['í˜‘ì—…í›„ê¸°_ì •ì œí…ìŠ¤íŠ¸'] = [r['refined_text'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ë¹„ì‹ë³„ì²˜ë¦¬'] = [r['is_anonymized'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ì£¼ê°ì •'] = [r['primary_sentiment'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ì„¸ë¶€ê°ì •'] = [r['detailed_sentiment'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ê°ì •ê°•ë„'] = [r['sentiment_intensity'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_í‚¤ì›Œë“œ'] = [', '.join(r['keywords']) for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ë¶„ë¥˜ë¼ë²¨'] = [', '.join(r['labels']) for r in results]
        
        # 5. ê²°ê³¼ íŒŒì¼ ì €ì¥
        output_file = "í˜‘ì—…í›„ê¸°_ë¶„ì„ê²°ê³¼_ìƒìœ„200ê±´.xlsx"
        feedback_df.to_excel(output_file, index=False, engine='openpyxl')
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")
        
        # 6. ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        sentiment_counts = pd.Series([r['primary_sentiment'] for r in results]).value_counts()
        for sentiment, count in sentiment_counts.items():
            print(f"  {sentiment}: {count}ê±´ ({count/len(results)*100:.1f}%)")
        
        return feedback_df, results
        
    except Exception as e:
        import traceback
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()