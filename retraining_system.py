"""
ì¬í•™ìŠµ ì‹œìŠ¤í…œ (Advanced Learning System)
- ìˆ˜ì • íŒ¨í„´ ìë™ ë¶„ì„
- í”„ë¡¬í”„íŠ¸ ìë™ ìµœì í™”
- ì„±ëŠ¥ ì§€ì†ì  ê°œì„ 
"""

import pandas as pd
import numpy as np
from collections import Counter, defaultdict
import json
import re
from datetime import datetime

class RetrainingSystem:
    """AI ì¬í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.correction_patterns = {}
        self.performance_metrics = {}
        self.learning_history = []
        self.optimized_prompt = None
    
    def analyze_corrections(self, original_file, corrected_file):
        """ìˆ˜ì • ì „í›„ ë°ì´í„° ë¹„êµ ë¶„ì„"""
        
        print("ğŸ” ìˆ˜ì • íŒ¨í„´ ë¶„ì„ ì‹œì‘...")
        
        # ì›ë³¸ê³¼ ìˆ˜ì •ë³¸ ë¡œë“œ
        df_original = pd.read_excel(original_file)
        df_corrected = pd.read_excel(corrected_file)
        
        # ìˆ˜ì •ëœ í•­ëª© ì‹ë³„
        corrections = self._identify_corrections(df_original, df_corrected)
        
        # íŒ¨í„´ ë¶„ì„
        patterns = self._extract_patterns(corrections)
        
        # ì„±ëŠ¥ ê°œì„  ë¶„ì„
        improvements = self._analyze_improvements(df_original, df_corrected)
        
        self.correction_patterns = patterns
        self.performance_metrics = improvements
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(corrections)}ê°œ ìˆ˜ì • ì‚¬í•­ ë°œê²¬")
        
        return {
            'corrections': corrections,
            'patterns': patterns,
            'improvements': improvements
        }
    
    def _identify_corrections(self, df_original, df_corrected):
        """ìˆ˜ì • í•­ëª© ì‹ë³„"""
        
        corrections = []
        
        for idx in df_original.index:
            if idx >= len(df_corrected):
                continue
                
            original_row = df_original.iloc[idx]
            corrected_row = df_corrected.iloc[idx]
            
            # ë³€ê²½ ì‚¬í•­ í™•ì¸
            changes = {}
            
            fields_to_check = ['ì •ì œí…ìŠ¤íŠ¸', 'ê°ì •ë¶„ì„', 'ê°ì •ê°•ë„', 'ë¶„ë¥˜ë¼ë²¨', 'í’ˆì§ˆì ìˆ˜']
            
            for field in fields_to_check:
                if field in original_row and field in corrected_row:
                    if original_row[field] != corrected_row[field]:
                        changes[field] = {
                            'before': original_row[field],
                            'after': corrected_row[field]
                        }
            
            if changes:
                correction = {
                    'index': idx,
                    'original_text': original_row['í˜‘ì—… í›„ê¸°'],
                    'changes': changes,
                    'reason': corrected_row.get('ìˆ˜ì •ì‚¬ìœ ', 'Unknown')
                }
                corrections.append(correction)
        
        return corrections
    
    def _extract_patterns(self, corrections):
        """ìˆ˜ì • íŒ¨í„´ ì¶”ì¶œ"""
        
        patterns = {
            'sentiment_changes': defaultdict(int),
            'label_changes': defaultdict(int),
            'common_keywords': defaultdict(int),
            'quality_improvements': [],
            'text_refinements': []
        }
        
        for correction in corrections:
            changes = correction['changes']
            original_text = correction['original_text']
            
            # ê°ì • ë¶„ì„ ë³€ê²½ íŒ¨í„´
            if 'ê°ì •ë¶„ì„' in changes:
                before = changes['ê°ì •ë¶„ì„']['before']
                after = changes['ê°ì •ë¶„ì„']['after']
                patterns['sentiment_changes'][f"{before}â†’{after}"] += 1
            
            # ë¶„ë¥˜ ë¼ë²¨ ë³€ê²½ íŒ¨í„´
            if 'ë¶„ë¥˜ë¼ë²¨' in changes:
                before = changes['ë¶„ë¥˜ë¼ë²¨']['before']
                after = changes['ë¶„ë¥˜ë¼ë²¨']['after']
                patterns['label_changes'][f"{before}â†’{after}"] += 1
            
            # í‚¤ì›Œë“œ ë¶„ì„
            if isinstance(original_text, str):
                keywords = self._extract_keywords(original_text)
                for keyword in keywords:
                    patterns['common_keywords'][keyword] += 1
            
            # í’ˆì§ˆ ê°œì„ 
            if 'í’ˆì§ˆì ìˆ˜' in changes:
                before = changes['í’ˆì§ˆì ìˆ˜']['before']
                after = changes['í’ˆì§ˆì ìˆ˜']['after']
                improvement = after - before
                patterns['quality_improvements'].append(improvement)
            
            # í…ìŠ¤íŠ¸ ì •ì œ íŒ¨í„´
            if 'ì •ì œí…ìŠ¤íŠ¸' in changes:
                before = changes['ì •ì œí…ìŠ¤íŠ¸']['before']
                after = changes['ì •ì œí…ìŠ¤íŠ¸']['after']
                patterns['text_refinements'].append({
                    'before': before,
                    'after': after,
                    'original': original_text
                })
        
        return patterns
    
    def _extract_keywords(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        
        if not isinstance(text, str):
            return []
        
        # í•œêµ­ì–´ í‚¤ì›Œë“œ íŒ¨í„´
        keywords = []
        
        # ì£¼ìš” ë‹¨ì–´ íŒ¨í„´
        patterns = [
            r'ì—…ë¬´.*?ì²˜ë¦¬',
            r'ì •ë³´.*?ê³µìœ ',
            r'ì˜ì‚¬ì†Œí†µ',
            r'í˜‘ì—…',
            r'íƒœë„',
            r'ì„œë¹„ìŠ¤',
            r'ì „ë¬¸ì„±',
            r'ì‹ ì†',
            r'ì •í™•',
            r'ì¹œì ˆ',
            r'ë¶ˆì¹œì ˆ',
            r'ì§€ì—°',
            r'ê°œì„ ',
            r'ë§Œì¡±',
            r'ë¶ˆë§Œ',
            r'ê°ì‚¬'
        ]
        
        for pattern in patterns:
            if re.search(pattern, text):
                keywords.append(pattern.replace('.*?', ' '))
        
        return keywords
    
    def _analyze_improvements(self, df_original, df_corrected):
        """ì„±ëŠ¥ ê°œì„  ë¶„ì„"""
        
        improvements = {}
        
        # í’ˆì§ˆì ìˆ˜ ê°œì„ 
        if 'í’ˆì§ˆì ìˆ˜' in df_original.columns and 'í’ˆì§ˆì ìˆ˜' in df_corrected.columns:
            original_quality = df_original['í’ˆì§ˆì ìˆ˜'].mean()
            corrected_quality = df_corrected['í’ˆì§ˆì ìˆ˜'].mean()
            improvements['quality_improvement'] = corrected_quality - original_quality
        
        # ì¬ê²€í†  í•„ìš” í•­ëª© ê°ì†Œ
        if 'ì¬ê²€í† í•„ìš”' in df_original.columns and 'ì¬ê²€í† í•„ìš”' in df_corrected.columns:
            original_review_needed = df_original['ì¬ê²€í† í•„ìš”'].sum()
            corrected_review_needed = df_corrected['ì¬ê²€í† í•„ìš”'].sum()
            improvements['review_reduction'] = original_review_needed - corrected_review_needed
        
        # ê°ì • ë¶„ì„ ì •í™•ë„ (ì¶”ì •)
        improvements['estimated_accuracy'] = self._estimate_accuracy_improvement()
        
        return improvements
    
    def _estimate_accuracy_improvement(self):
        """ì •í™•ë„ ê°œì„  ì¶”ì •"""
        
        # ìˆ˜ì • íŒ¨í„´ ê¸°ë°˜ ì •í™•ë„ ì¶”ì •
        if not self.correction_patterns:
            return 0
        
        sentiment_changes = self.correction_patterns.get('sentiment_changes', {})
        total_changes = sum(sentiment_changes.values())
        
        if total_changes == 0:
            return 0
        
        # ë¶€ì •â†’ì¤‘ë¦½, ì¤‘ë¦½â†’ê¸ì • ë“±ì˜ ê°œì„  íŒ¨í„´ ë¹„ìœ¨ ê³„ì‚°
        positive_changes = 0
        for change, count in sentiment_changes.items():
            if 'ë¶€ì •â†’ì¤‘ë¦½' in change or 'ì¤‘ë¦½â†’ê¸ì •' in change:
                positive_changes += count
        
        improvement_ratio = positive_changes / total_changes
        return improvement_ratio * 100  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    
    def generate_optimized_prompt(self):
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        if not self.correction_patterns:
            print("âŒ ë¶„ì„ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € analyze_correctionsë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        print("ğŸš€ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        base_prompt = """
[í˜ë¥´ì†Œë‚˜]
ë‹¹ì‹ ì€ ë‚´ë¶€ ì§ì› ë§Œì¡±ë„ ë° í˜‘ì—… í”¼ë“œë°±ì„ ë¶„ì„í•˜ëŠ”, ë§¤ìš° ê¼¼ê¼¼í•˜ê³  ì •í™•í•œ AI ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ í•™ìŠµëœ íŒ¨í„´ì„ ë°˜ë“œì‹œ ì ìš©í•˜ì—¬ ì •í™•í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
"""
        
        # í•™ìŠµëœ íŒ¨í„´ ì¶”ê°€
        pattern_section = self._generate_pattern_rules()
        
        # ê°œì„ ëœ ì§€ì‹œì‚¬í•­
        improved_instructions = self._generate_improved_instructions()
        
        # í’ˆì§ˆ ê¸°ì¤€ ê°•í™”
        quality_standards = self._generate_quality_standards()
        
        optimized_prompt = f"""
{base_prompt}

{pattern_section}

{improved_instructions}

{quality_standards}

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "refined_text": "ì •ì œëœ í…ìŠ¤íŠ¸",
    "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
    "sentiment_intensity": 1-10,
    "classification": "ë¶„ë¥˜ë¼ë²¨",
    "confidence_score": 1-10,
    "requires_review": true/false,
    "anonymized": true/false
}}
"""
        
        self.optimized_prompt = optimized_prompt
        
        # í•™ìŠµ ì´ë ¥ ì €ì¥
        self._save_learning_history()
        
        print("âœ… ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
        
        return optimized_prompt
    
    def _generate_pattern_rules(self):
        """íŒ¨í„´ ê¸°ë°˜ ê·œì¹™ ìƒì„±"""
        
        rules = ["[í•™ìŠµëœ íŒ¨í„´ ê·œì¹™]"]
        
        # ê°ì • ë¶„ì„ íŒ¨í„´
        sentiment_patterns = self.correction_patterns.get('sentiment_changes', {})
        if sentiment_patterns:
            rules.append("\\n**ê°ì • ë¶„ì„ ê°œì„  ê·œì¹™:**")
            
            most_common = sorted(sentiment_patterns.items(), key=lambda x: x[1], reverse=True)[:3]
            
            for pattern, count in most_common:
                if 'ë¶€ì •â†’ì¤‘ë¦½' in pattern:
                    rules.append("- ì—…ë¬´ ê°œì„  ì œì•ˆì´ë‚˜ ê±´ì„¤ì  í”¼ë“œë°±ì€ 'ì¤‘ë¦½'ìœ¼ë¡œ ë¶„ë¥˜")
                elif 'ë¶€ì •â†’ê¸ì •' in pattern:
                    rules.append("- í˜‘ë ¥ì ì´ê³  ê¸ì •ì ì¸ í‘œí˜„ì€ 'ê¸ì •'ìœ¼ë¡œ ë¶„ë¥˜")
                elif 'ì¤‘ë¦½â†’ë¶€ì •' in pattern:
                    rules.append("- ëª…í™•í•œ ë¶ˆë§Œì´ë‚˜ ë¹„íŒì€ 'ë¶€ì •'ìœ¼ë¡œ ë¶„ë¥˜")
        
        # ë¶„ë¥˜ ë¼ë²¨ íŒ¨í„´
        label_patterns = self.correction_patterns.get('label_changes', {})
        if label_patterns:
            rules.append("\\n**ë¶„ë¥˜ ë¼ë²¨ ê°œì„  ê·œì¹™:**")
            
            most_common = sorted(label_patterns.items(), key=lambda x: x[1], reverse=True)[:3]
            
            for pattern, count in most_common:
                rules.append(f"- {pattern.replace('â†’', ' â†’ ')}: {count}ê±´ ìˆ˜ì •ë¨")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê·œì¹™
        common_keywords = self.correction_patterns.get('common_keywords', {})
        if common_keywords:
            rules.append("\\n**í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê·œì¹™:**")
            
            top_keywords = sorted(common_keywords.items(), key=lambda x: x[1], reverse=True)[:5]
            
            for keyword, count in top_keywords:
                if 'ì—…ë¬´' in keyword:
                    rules.append(f"- '{keyword}' í¬í•¨ ì‹œ â†’ ì „ë¬¸ì„± ë¶€ì¡± ë˜ëŠ” ì—…ë¬´ íƒœë„")
                elif 'ì •ë³´' in keyword:
                    rules.append(f"- '{keyword}' í¬í•¨ ì‹œ â†’ ì§ì›ê°„ ì†Œí†µ")
                elif 'í˜‘ì—…' in keyword:
                    rules.append(f"- '{keyword}' í¬í•¨ ì‹œ â†’ ë¶€ì„œê°„ í˜‘ì—…")
        
        return "\\n".join(rules)
    
    def _generate_improved_instructions(self):
        """ê°œì„ ëœ ì§€ì‹œì‚¬í•­ ìƒì„±"""
        
        instructions = """
[ê°œì„ ëœ ë¶„ì„ ì§€ì‹œì‚¬í•­]

1. **ì •ì œí…ìŠ¤íŠ¸ ìƒì„± ê·œì¹™:**
   - ì›ë³¸ ì˜ë¯¸ë¥¼ 100% ë³´ì¡´í•˜ë©´ì„œ í‘œí˜„ë§Œ ê°œì„ 
   - ë¹„ì†ì–´ë‚˜ ë¶€ì ì ˆí•œ í‘œí˜„ì€ ì „ë¬¸ì  í‘œí˜„ìœ¼ë¡œ ë³€ê²½
   - ì˜¤íƒ€ ë° ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •
   - ë¶ˆì™„ì „í•œ ë¬¸ì¥ì€ ì™„ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ë³´ì™„

2. **ê°ì •ë¶„ì„ ì •í™•ë„ í–¥ìƒ:**
   - ì—…ë¬´ ê°œì„  ì œì•ˆ = ì¤‘ë¦½ (ë¶€ì • ì•„ë‹˜)
   - ì‚¬ì‹¤ì  ê¸°ìˆ  = ì¤‘ë¦½
   - ëª…í™•í•œ ì¹­ì°¬/ê°ì‚¬ = ê¸ì •
   - ëª…í™•í•œ ë¶ˆë§Œ/ë¹„íŒ = ë¶€ì •

3. **ë¶„ë¥˜ë¼ë²¨ ì •í™•ì„± í–¥ìƒ:**
   - ì •ë³´ ì „ë‹¬/ê³µìœ  ë¬¸ì œ â†’ ì§ì›ê°„ ì†Œí†µ
   - ì—…ë¬´ ì²˜ë¦¬ ì†ë„/ì •í™•ì„± â†’ ì „ë¬¸ì„± ë¶€ì¡±
   - ì„œë¹„ìŠ¤ íƒœë„/ì¹œì ˆë„ â†’ ì—…ë¬´ íƒœë„
   - ë¶€ì„œê°„ ì¡°ìœ¨/í˜‘ë ¥ â†’ ë¶€ì„œê°„ í˜‘ì—…
   - ì˜ˆì˜/ë°°ë ¤/ì¡´ì¤‘ â†’ ìƒí˜¸ ì¡´ì¤‘

4. **í’ˆì§ˆì ìˆ˜ ê¸°ì¤€ ê°•í™”:**
   - ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©: 8-10ì 
   - ì¼ë°˜ì ì´ì§€ë§Œ ì˜ë¯¸ìˆëŠ” ë‚´ìš©: 6-7ì 
   - ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•œ ë‚´ìš©: 4-5ì 
   - ì˜ë¯¸ íŒŒì•… ì–´ë ¤ìš´ ë‚´ìš©: 1-3ì 
"""
        
        return instructions
    
    def _generate_quality_standards(self):
        """í’ˆì§ˆ ê¸°ì¤€ ìƒì„±"""
        
        avg_improvement = np.mean(self.correction_patterns.get('quality_improvements', [0]))
        
        standards = f"""
[í’ˆì§ˆ ë³´ì¦ ê¸°ì¤€]

ëª©í‘œ ì„±ëŠ¥:
- í’ˆì§ˆì ìˆ˜ 7ì  ì´ìƒ: 90% ì´ìƒ
- ì¬ê²€í†  í•„ìš” í•­ëª©: 5% ì´í•˜
- ê°ì •ë¶„ì„ ì •í™•ë„: 95% ì´ìƒ

í’ˆì§ˆ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:
â–¡ ì •ì œí…ìŠ¤íŠ¸ê°€ ì›ë³¸ ì˜ë¯¸ë¥¼ ì •í™•íˆ ë°˜ì˜í•˜ëŠ”ê°€?
â–¡ ê°ì •ë¶„ì„ì´ í…ìŠ¤íŠ¸ í†¤ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?
â–¡ ë¶„ë¥˜ë¼ë²¨ì´ ë‚´ìš©ì˜ í•µì‹¬ì„ ë°˜ì˜í•˜ëŠ”ê°€?
â–¡ í’ˆì§ˆì ìˆ˜ê°€ ë¶„ì„ ì‹ ë¢°ë„ë¥¼ ì •í™•íˆ ë‚˜íƒ€ë‚´ëŠ”ê°€?

ìë™ ì¬ê²€í†  ì¡°ê±´:
- í’ˆì§ˆì ìˆ˜ 6ì  ì´í•˜
- ê°ì •ê°•ë„ì™€ ê°ì •ë¶„ì„ ë¶ˆì¼ì¹˜
- í‚¤ì›Œë“œì™€ ë¶„ë¥˜ë¼ë²¨ ë¶ˆì¼ì¹˜

ëª©í‘œ ê°œì„ ìœ¨: {avg_improvement:.1f}ì  í–¥ìƒ
"""
        
        return standards
    
    def _save_learning_history(self):
        """í•™ìŠµ ì´ë ¥ ì €ì¥"""
        
        history_entry = {
            'timestamp': datetime.now().isoformat(),
            'patterns_analyzed': len(self.correction_patterns),
            'performance_metrics': self.performance_metrics,
            'prompt_version': f"v{len(self.learning_history) + 1}"
        }
        
        self.learning_history.append(history_entry)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open('learning_history.json', 'w', encoding='utf-8') as f:
            json.dump(self.learning_history, f, ensure_ascii=False, indent=2)
    
    def evaluate_performance(self, test_file):
        """ì„±ëŠ¥ í‰ê°€"""
        
        print("ğŸ“Š ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")
        
        df_test = pd.read_excel(test_file)
        
        metrics = {
            'total_items': len(df_test),
            'high_quality_ratio': len(df_test[df_test['í’ˆì§ˆì ìˆ˜'] >= 7]) / len(df_test),
            'review_needed_ratio': df_test['ì¬ê²€í† í•„ìš”'].sum() / len(df_test),
            'average_quality': df_test['í’ˆì§ˆì ìˆ˜'].mean(),
            'sentiment_distribution': df_test['ê°ì •ë¶„ì„'].value_counts().to_dict()
        }
        
        print("ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
        print(f"  â€¢ ì „ì²´ í•­ëª©: {metrics['total_items']}ê°œ")
        print(f"  â€¢ ê³ í’ˆì§ˆ ë¹„ìœ¨: {metrics['high_quality_ratio']:.1%}")
        print(f"  â€¢ ì¬ê²€í†  í•„ìš” ë¹„ìœ¨: {metrics['review_needed_ratio']:.1%}")
        print(f"  â€¢ í‰ê·  í’ˆì§ˆì ìˆ˜: {metrics['average_quality']:.1f}ì ")
        
        return metrics
    
    def continuous_learning_cycle(self, original_file, corrected_file, new_data_file):
        """ì§€ì†ì  í•™ìŠµ ì‚¬ì´í´"""
        
        print("ğŸ”„ ì§€ì†ì  í•™ìŠµ ì‚¬ì´í´ ì‹œì‘...")
        
        # 1ë‹¨ê³„: ìˆ˜ì • íŒ¨í„´ ë¶„ì„
        analysis = self.analyze_corrections(original_file, corrected_file)
        
        # 2ë‹¨ê³„: ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        optimized_prompt = self.generate_optimized_prompt()
        
        # 3ë‹¨ê³„: ìƒˆë¡œìš´ ë°ì´í„°ì— ì ìš© (ì‹œë®¬ë ˆì´ì…˜)
        print("3ë‹¨ê³„: ìµœì í™”ëœ ëª¨ë¸ë¡œ ìƒˆ ë°ì´í„° ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)")
        
        # 4ë‹¨ê³„: ì„±ëŠ¥ í‰ê°€
        if corrected_file:
            performance = self.evaluate_performance(corrected_file)
        
        # 5ë‹¨ê³„: ê²°ê³¼ ë¦¬í¬íŠ¸
        self._generate_learning_report(analysis, performance if 'performance' in locals() else None)
        
        return {
            'analysis': analysis,
            'optimized_prompt': optimized_prompt,
            'performance': performance if 'performance' in locals() else None
        }
    
    def _generate_learning_report(self, analysis, performance):
        """í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        report = f"""
# ğŸ“ AI ì¬í•™ìŠµ ê²°ê³¼ ë¦¬í¬íŠ¸

## ğŸ“Š í•™ìŠµ ê°œìš”
- **ë¶„ì„ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ìˆ˜ì • ì‚¬í•­**: {len(analysis['corrections'])}ê±´
- **í•™ìŠµëœ íŒ¨í„´**: {len(analysis['patterns'])}ê°œ ìœ í˜•

## ğŸ” ì£¼ìš” ê°œì„  ì‚¬í•­
"""
        
        # ê°ì • ë¶„ì„ ê°œì„ 
        sentiment_changes = analysis['patterns'].get('sentiment_changes', {})
        if sentiment_changes:
            report += "\\n### ê°ì • ë¶„ì„ ê°œì„ \\n"
            for change, count in sorted(sentiment_changes.items(), key=lambda x: x[1], reverse=True)[:3]:
                report += f"- {change}: {count}ê±´\\n"
        
        # ë¶„ë¥˜ ê°œì„ 
        label_changes = analysis['patterns'].get('label_changes', {})
        if label_changes:
            report += "\\n### ë¶„ë¥˜ ë¼ë²¨ ê°œì„ \\n"
            for change, count in sorted(label_changes.items(), key=lambda x: x[1], reverse=True)[:3]:
                report += f"- {change}: {count}ê±´\\n"
        
        # ì„±ëŠ¥ ì§€í‘œ
        if performance:
            report += f"""
## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ
- **ê³ í’ˆì§ˆ ë¹„ìœ¨**: {performance['high_quality_ratio']:.1%}
- **ì¬ê²€í†  í•„ìš”**: {performance['review_needed_ratio']:.1%}
- **í‰ê·  í’ˆì§ˆì ìˆ˜**: {performance['average_quality']:.1f}ì 
"""
        
        # íŒŒì¼ ì €ì¥
        with open('learning_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("ğŸ“„ í•™ìŠµ ë¦¬í¬íŠ¸ê°€ 'learning_report.md'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def demo_retraining_system():
    """ì¬í•™ìŠµ ì‹œìŠ¤í…œ ë°ëª¨"""
    
    print("ğŸ¯ AI ì¬í•™ìŠµ ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 50)
    
    # ì¬í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    retraining = RetrainingSystem()
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    print("ğŸ“š í•™ìŠµ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜...")
    
    # ëª¨ì˜ ìˆ˜ì • íŒ¨í„´ ìƒì„±
    retraining.correction_patterns = {
        'sentiment_changes': {
            'ë¶€ì •â†’ì¤‘ë¦½': 15,
            'ì¤‘ë¦½â†’ê¸ì •': 8,
            'ë¶€ì •â†’ê¸ì •': 3
        },
        'label_changes': {
            'ì—…ë¬´ íƒœë„â†’ì§ì›ê°„ ì†Œí†µ': 12,
            'ì „ë¬¸ì„± ë¶€ì¡±â†’ì—…ë¬´ íƒœë„': 7,
            'ë¶€ì„œê°„ í˜‘ì—…â†’ìƒí˜¸ ì¡´ì¤‘': 5
        },
        'quality_improvements': [2.1, 1.8, 2.5, 1.2, 3.0],
        'common_keywords': {
            'ì—…ë¬´ ì²˜ë¦¬': 20,
            'ì •ë³´ ê³µìœ ': 15,
            'ì˜ì‚¬ì†Œí†µ': 12,
            'í˜‘ì—…': 10,
            'íƒœë„': 8
        }
    }
    
    # ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
    optimized_prompt = retraining.generate_optimized_prompt()
    
    if optimized_prompt:
        print("\\nâœ… ì¬í•™ìŠµ ì™„ë£Œ!")
        print("ğŸ“Š í•™ìŠµ ê²°ê³¼:")
        print(f"  â€¢ ê°ì • ë¶„ì„ íŒ¨í„´: {len(retraining.correction_patterns['sentiment_changes'])}ê°œ")
        print(f"  â€¢ ë¶„ë¥˜ ê°œì„  íŒ¨í„´: {len(retraining.correction_patterns['label_changes'])}ê°œ")
        print(f"  â€¢ í‰ê·  í’ˆì§ˆ ê°œì„ : {np.mean(retraining.correction_patterns['quality_improvements']):.1f}ì ")
        
        return retraining
    else:
        print("âŒ ì¬í•™ìŠµ ì‹¤íŒ¨")
        return None

if __name__ == "__main__":
    demo_retraining_system()