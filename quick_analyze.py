import pandas as pd
import json
import time
from pathlib import Path
import vertexai
from vertexai.generative_models import GenerativeModel
import warnings
warnings.filterwarnings('ignore')

# ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
QUICK_PROMPT_TEMPLATE = """
[ë¶„ì„ ì§€ì‹œì‚¬í•­]
ë‹¤ìŒ í˜‘ì—… í›„ê¸°ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”.

[ê°ì • ë¶„ì„]
- primary_sentiment: "ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½" ì¤‘ í•˜ë‚˜
- detailed_sentiment: ê¸ì •(ê°ì‚¬,ë§Œì¡±,ì¹­ì°¬), ë¶€ì •(ë¶ˆë§Œ,ì‹¤ë§,ë¹„íŒ), ì¤‘ë¦½(ì œì•ˆ,ì •ë³´,ê¸°íƒ€)
- sentiment_intensity: 1-10 ì ìˆ˜ (1-2:ë§¤ìš°ì•½í•¨, 3-4:ì•½í•¨, 5-6:ë³´í†µ, 7-8:ê°•í•¨, 9-10:ë§¤ìš°ê°•í•¨)

[í‚¤ì›Œë“œ ë° ë¶„ë¥˜]
- keywords: í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ
- labels: í•´ë‹¹í•˜ëŠ” ë¶„ë¥˜ ("ë¶€ì„œê°„ í˜‘ì—…", "ì§ì›ê°„ ì†Œí†µ", "ì—…ë¬´ íƒœë„", "ì‹œìŠ¤í…œ/í”„ë¡œì„¸ìŠ¤" ë“±)

[ì¶œë ¥ í˜•ì‹]
{{
  "refined_text": "ì •ì œëœ í…ìŠ¤íŠ¸",
  "is_anonymized": false,
  "primary_sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "detailed_sentiment": "ì„¸ë¶€ê°ì •",
  "sentiment_intensity": ê°ì •ê°•ë„ì ìˆ˜(1-10),
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
  "labels": ["ë¼ë²¨1", "ë¼ë²¨2"]
}}

ì›ë³¸ í…ìŠ¤íŠ¸: "{original_text}"
"""

class QuickAnalyzer:
    def __init__(self, project_id: str, location: str = "us-central1"):
        vertexai.init(project=project_id, location=location)
        self.model = GenerativeModel("gemini-2.0-flash")
    
    def analyze_review(self, original_text: str) -> dict:
        """ë¹ ë¥¸ ë¦¬ë·° ë¶„ì„"""
        if not original_text or str(original_text).strip() == "":
            return {
                "refined_text": "",
                "is_anonymized": False,
                "primary_sentiment": "ì¤‘ë¦½",
                "detailed_sentiment": "ê¸°íƒ€",
                "sentiment_intensity": 5,
                "keywords": [],
                "labels": []
            }
        
        processed_text = str(original_text).strip()
        prompt = QUICK_PROMPT_TEMPLATE.format(original_text=processed_text)
        
        try:
            response = self.model.generate_content(prompt)
            response_text = response.text.strip()
            
            # JSON íŒŒì‹±
            try:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_text = response_text[json_start:json_end]
                    result = json.loads(json_text)
                    return result
                else:
                    raise json.JSONDecodeError("No JSON found", response_text, 0)
                    
            except json.JSONDecodeError:
                return self._create_fallback_result(processed_text)
                
        except Exception as e:
            return self._create_fallback_result(processed_text)
    
    def _create_fallback_result(self, processed_text: str) -> dict:
        """API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±"""
        return {
            "refined_text": processed_text,
            "is_anonymized": False,
            "primary_sentiment": "ì¤‘ë¦½",
            "detailed_sentiment": "ê¸°íƒ€",
            "sentiment_intensity": 5,
            "keywords": [],
            "labels": []
        }

def main():
    print("âš¡ ë¹ ë¥¸ í˜‘ì—… í›„ê¸° 200ê±´ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    try:
        # 1. ì›ë³¸ íŒŒì¼ ë¡œë”©
        print("ğŸ“ ì›ë³¸ íŒŒì¼ ë¡œë”©...")
        df = pd.read_excel('ì„¤ë¬¸ì¡°ì‚¬_ì „ì²˜ë¦¬ë°ì´í„°_20250620_0731.xlsx', engine='openpyxl')
        
        # 2. í˜‘ì—… í›„ê¸° ë°ì´í„° ì¶”ì¶œ (ìƒìœ„ 200ê±´)
        print("ğŸ“Š í˜‘ì—… í›„ê¸° ë°ì´í„° ì¶”ì¶œ...")
        feedback_mask = df['í˜‘ì—… í›„ê¸°'].notna() & (df['í˜‘ì—… í›„ê¸°'].str.len() > 0)
        feedback_df = df[feedback_mask].head(200).copy()
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(feedback_df)}ê±´")
        
        # 3. AI ë¶„ì„ê¸° ì´ˆê¸°í™”
        print("ğŸ¤– AI ë¶„ì„ê¸° ì´ˆê¸°í™”...")
        analyzer = QuickAnalyzer(project_id="angelic-hold-456808-d2")
        
        print(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘ (ì´ {len(feedback_df)}ê±´)")
        
        results = []
        for i, (idx, row) in enumerate(feedback_df.iterrows(), 1):
            if i % 10 == 0:
                print(f"[{i}/{len(feedback_df)}] ì§„í–‰ë¥ : {i/len(feedback_df)*100:.1f}%")
            
            original_text = str(row['í˜‘ì—… í›„ê¸°'])
            result = analyzer.analyze_review(original_text)
            results.append(result)
            
            # API í˜¸ì¶œ ì œí•œ ì™„í™”
            time.sleep(0.05)
        
        # 4. ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ì¶”ê°€
        print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼ë¥¼ ì›ë³¸ ì‹œíŠ¸ì— ì¶”ê°€...")
        
        feedback_df['í˜‘ì—…í›„ê¸°_ì •ì œí…ìŠ¤íŠ¸'] = [r['refined_text'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ë¹„ì‹ë³„ì²˜ë¦¬'] = [r['is_anonymized'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ì£¼ê°ì •'] = [r['primary_sentiment'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ì„¸ë¶€ê°ì •'] = [r['detailed_sentiment'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ê°ì •ê°•ë„'] = [r['sentiment_intensity'] for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_í‚¤ì›Œë“œ'] = [', '.join(r['keywords']) for r in results]
        feedback_df['í˜‘ì—…í›„ê¸°_ë¶„ë¥˜ë¼ë²¨'] = [', '.join(r['labels']) for r in results]
        
        # 5. ê²°ê³¼ íŒŒì¼ ì €ì¥
        output_file = "í˜‘ì—…í›„ê¸°_ë¶„ì„ê²°ê³¼_ìƒìœ„200ê±´.xlsx"
        feedback_df.to_excel(output_file, index=False, engine='openpyxl')
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")
        
        # 6. ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        sentiment_counts = pd.Series([r['primary_sentiment'] for r in results]).value_counts()
        for sentiment, count in sentiment_counts.items():
            print(f"  {sentiment}: {count}ê±´ ({count/len(results)*100:.1f}%)")
        
        return feedback_df, results
        
    except Exception as e:
        import traceback
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()