#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Local version of the Colab environment analyzer
Adapted from í˜‘ì—…í‰ê°€_250619.ipynb for local execution

This script provides the same functionality as the Colab notebook
but adapted for local environment without Google Colab dependencies.
"""

import pandas as pd
import datetime
from pathlib import Path
import numpy as np
import re
import time
import unicodedata
import os
import logging

# Google Cloud libraries (available in local environment)
import vertexai
from vertexai.generative_models import GenerativeModel
from tqdm.auto import tqdm

# Enable tqdm integration with pandas
tqdm.pandas()

class LocalGoogleSheetsAnalyzer:
    """Local version of the Google Sheets analyzer from Colab"""

    def __init__(self, base_path: str, mapping_file_path: str = None, output_path: str = None, **kwargs):
        self.base_path = Path(base_path)
        self.mapping_file_path = mapping_file_path
        self.standard_map_path = kwargs.get('standard_map_path')
        self.output_path = Path(output_path) if output_path else Path(base_path).parent
        self.department_mapping = {}
        self.department_standard_map = {}
        self.enhanced_mapping = {}  # ë¶€ì„œëª…+Unit ì¡°í•©ë³„ ë§¤í•‘
        self.labeling_stats = {
            'dept_unit_match': 0,
            'dept_only_match': 0, 
            'dept_not_found': 0,
            'unit_mismatch': 0
        }

        self.question_columns = [
            'â—‹â—‹ì€ íƒ€ ë¶€ì„œì˜ ì…ì¥ì„ ì¡´ì¤‘í•˜ê³  ë°°ë ¤í•˜ì—¬ í˜‘ë ¥í•´ì£¼ë©°. í˜‘ì—… ê´€ë ¨ ì˜ê²¬ì„ ê²½ì²­í•´ì¤€ë‹¤.',
            'â—‹â—‹ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ì •ë³´ì— ëŒ€í•´ ê³µìœ ê°€ ì˜ ì´ë£¨ì–´ì§„ë‹¤.',
            'â—‹â—‹ì€ ì—…ë¬´ì— ëŒ€í•œ ëª…í™•í•œ ë‹´ë‹¹ìê°€ ìˆê³  ì—…ë¬´ë¥¼ ì¼ê´€ì„±ìˆê²Œ ì²˜ë¦¬í•´ì¤€ë‹¤.',
            'â—‹â—‹ì€ ì´ì „ë³´ë‹¤ ì—…ë¬´ í˜‘ë ¥ì— ëŒ€í•œ íƒœë„ë‚˜ ì˜ì§€ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.',
            'ì „ë°˜ì ìœ¼ë¡œ â—‹â—‹ê³¼ì˜ í˜‘ì—…ì— ëŒ€í•´ ë§Œì¡±í•œë‹¤.'
        ]

    def load_department_standard_map(self):
        """ë¶€ì„œëª… í‘œì¤€í™” ë§¤í•‘ ë¡œë“œ"""
        if not self.standard_map_path or not Path(self.standard_map_path).exists():
            print(f"âš ï¸ ë¶€ì„œëª… í‘œì¤€í™” ë§¤í•‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¶€ì„œëª…ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return
        try:
            map_df = pd.read_excel(self.standard_map_path)
            if 'ë³€ê²½ì „_ë¶€ì„œëª…' in map_df.columns and 'í‘œì¤€_ë¶€ì„œëª…' in map_df.columns:
                self.department_standard_map = dict(zip(map_df['ë³€ê²½ì „_ë¶€ì„œëª…'], map_df['í‘œì¤€_ë¶€ì„œëª…']))
                print(f"âœ… ë¶€ì„œëª… í‘œì¤€í™” ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.department_standard_map)}ê°œ")
        except Exception as e:
            print(f"âŒ ë¶€ì„œëª… í‘œì¤€í™” ë§¤í•‘ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")

    def normalize_string(self, text):
        """ë¬¸ìì—´ ì •ê·œí™” (ëŒ€ì†Œë¬¸ì, ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì í†µì¼)"""
        if pd.isna(text) or text == '':
            return ''
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜
        text = str(text).strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (ã†, Â·, â€¢, -, _ ë¥¼ ëª¨ë‘ ê³µë°±ìœ¼ë¡œ)
        text = re.sub(r'[ã†Â·â€¢\-_]', ' ', text)
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        
        # ëŒ€ì†Œë¬¸ì í†µì¼ (ì†Œë¬¸ìë¡œ)
        text = text.lower()
        
        return text.strip()

    def is_empty_unit(self, unit_value):
        """Unitì´ ë¹ˆ ê°’ì¸ì§€ í™•ì¸"""
        if pd.isna(unit_value):
            return True
        
        unit_str = str(unit_value).strip().lower()
        return unit_str in ['', 'n/a', 'na', 'null', 'none']

    def load_department_mapping(self):
        """ë¶€ì„œ-ë¶€ë¬¸ ë§¤í•‘ ë¡œë“œ (í‘œì¤€í™” ì ìš© ë²„ì „)"""
        if not self.mapping_file_path or not Path(self.mapping_file_path).exists(): 
            return
        try:
            mapping_df = pd.read_excel(self.mapping_file_path)
            print(f"ğŸ“‹ ë§¤í•‘ íŒŒì¼ ë¡œë“œ: {len(mapping_df)}ê°œ ë ˆì½”ë“œ")
            
            # ê¸°ë³¸ ë¶€ì„œëª… -> ë¶€ë¬¸ ë§¤í•‘ (í‘œì¤€í™” + ì •ê·œí™”ëœ í‚¤ ì‚¬ìš©)
            if 'ë¶€ì„œëª…' in mapping_df.columns and 'ë¶€ë¬¸' in mapping_df.columns:
                dept_mapping = mapping_df.dropna(subset=['ë¶€ì„œëª…', 'ë¶€ë¬¸']).copy()
                
                for _, row in dept_mapping.iterrows():
                    dept_name = row['ë¶€ì„œëª…']
                    
                    # 1ï¸âƒ£ í‘œì¤€í™” ì ìš© (ìˆëŠ” ê²½ìš°)
                    if self.department_standard_map and dept_name in self.department_standard_map:
                        standardized_dept = self.department_standard_map[dept_name]
                        print(f"ğŸ”„ ë¶€ì„œëª… í‘œì¤€í™” ì ìš©: '{dept_name}' â†’ '{standardized_dept}'")
                    else:
                        standardized_dept = dept_name
                    
                    # 2ï¸âƒ£ ì •ê·œí™” ì ìš©
                    norm_dept = self.normalize_string(standardized_dept)
                    
                    if norm_dept:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                        self.department_mapping[norm_dept] = row['ë¶€ë¬¸']
                
                print(f"âœ… ê¸°ë³¸ ë¶€ë¬¸ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.department_mapping)}ê°œ")
            
            # í–¥ìƒëœ ë¶€ì„œëª…+Unit -> ë¶€ë¬¸ ë§¤í•‘ (í‘œì¤€í™” ì ìš©)
            if all(col in mapping_df.columns for col in ['ë¶€ì„œëª…', 'ë¶€ë¬¸', 'ì†Œì†UNIT']):
                standardization_applied = 0
                
                for _, row in mapping_df.iterrows():
                    dept_name = row['ë¶€ì„œëª…']
                    division = row['ë¶€ë¬¸'] 
                    unit_name = row['ì†Œì†UNIT']
                    
                    if pd.notna(dept_name) and pd.notna(division):
                        # 1ï¸âƒ£ í‘œì¤€í™” ì ìš© (ìˆëŠ” ê²½ìš°)
                        original_dept_name = dept_name
                        if self.department_standard_map and dept_name in self.department_standard_map:
                            dept_name = self.department_standard_map[dept_name]
                            standardization_applied += 1
                        
                        # 2ï¸âƒ£ ì •ê·œí™” ì ìš©
                        norm_dept = self.normalize_string(dept_name)
                        
                        # Unitì´ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ ì €ì¥
                        if not self.is_empty_unit(unit_name):
                            norm_unit = self.normalize_string(unit_name)
                            key = f"{norm_dept}|{norm_unit}"
                            self.enhanced_mapping[key] = {
                                'division': division,
                                'original_dept': original_dept_name,  # ì›ë³¸ ë¶€ì„œëª… ìœ ì§€
                                'standardized_dept': dept_name,       # í‘œì¤€í™”ëœ ë¶€ì„œëª… ì¶”ê°€
                                'original_unit': unit_name,
                                'match_type': 'dept_unit'
                            }
                        
                        # ë¶€ì„œëª…ë§Œìœ¼ë¡œë„ ë§¤í•‘ ê°€ëŠ¥í•˜ë„ë¡ ì €ì¥ (Unit ì—†ëŠ” ê²½ìš°ìš©)
                        if norm_dept not in [k.split('|')[0] for k in self.enhanced_mapping.keys() if '|' in k]:
                            dept_only_key = f"{norm_dept}|"
                            self.enhanced_mapping[dept_only_key] = {
                                'division': division,
                                'original_dept': original_dept_name,  # ì›ë³¸ ë¶€ì„œëª… ìœ ì§€
                                'standardized_dept': dept_name,       # í‘œì¤€í™”ëœ ë¶€ì„œëª… ì¶”ê°€
                                'original_unit': None,
                                'match_type': 'dept_only'
                            }
                
                print(f"âœ… í–¥ìƒëœ ë¶€ë¬¸ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.enhanced_mapping)}ê°œ")
                if standardization_applied > 0:
                    print(f"ğŸ”„ ë¶€ì„œëª… í‘œì¤€í™” ì ìš©: {standardization_applied}ê°œ ë¶€ì„œ")
                
        except Exception as e:
            print(f"âŒ ë¶€ë¬¸ ë§¤í•‘ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")

    def enhanced_department_labeling(self, dept_name, unit_name):
        """í–¥ìƒëœ ë¶€ì„œ-ë¶€ë¬¸ ë¼ë²¨ë§ í•¨ìˆ˜ (í‘œì¤€í™” ì ìš©)
        
        ë¼ë²¨ë§ ê·œì¹™:
        1. ë¶€ì„œëª…ê³¼ ì†Œì†UNITì´ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ê²½ìš° â†’ í•´ë‹¹ ë¶€ë¬¸ìœ¼ë¡œ ë¼ë²¨ë§ (dept_unit_match)
        2. ë¶€ì„œëª…ì€ ì¼ì¹˜í•˜ì§€ë§Œ ì†Œì†UNITì´ ì—†ëŠ” ê²½ìš° â†’ í•´ë‹¹ ë¶€ë¬¸ìœ¼ë¡œ ë¼ë²¨ë§ (dept_only_match)
        3. ë¶€ì„œëª…ì€ ì¼ì¹˜í•˜ì§€ë§Œ ì†Œì†UNITì´ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš° â†’ 'ë¯¸ë¶„ë¥˜'ë¡œ ë¼ë²¨ë§ (unit_mismatch)
        4. ë¶€ì„œëª…ì´ ë§¤í•‘ íŒŒì¼ì— ì—†ëŠ” ê²½ìš° â†’ 'ë¯¸ë¶„ë¥˜'ë¡œ ë¼ë²¨ë§ (dept_not_found)
        """
        if pd.isna(dept_name) or dept_name == '':
            self.labeling_stats['dept_not_found'] += 1
            return 'ë¯¸ë¶„ë¥˜', 'dept_not_found'
        
        # 1ï¸âƒ£ í‘œì¤€í™” ì ìš© (ìˆëŠ” ê²½ìš°)
        original_dept_name = dept_name
        if self.department_standard_map and dept_name in self.department_standard_map:
            dept_name = self.department_standard_map[dept_name]
        
        # 2ï¸âƒ£ ì •ê·œí™” ì ìš©
        norm_dept = self.normalize_string(dept_name)
        norm_unit = self.normalize_string(unit_name) if not self.is_empty_unit(unit_name) else ''
        
        # 1. ë¶€ì„œëª…+Unit ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ê²½ìš° í™•ì¸
        if norm_unit:  # Unitì´ ìˆëŠ” ê²½ìš°
            dept_unit_key = f"{norm_dept}|{norm_unit}"
            if dept_unit_key in self.enhanced_mapping:
                match_info = self.enhanced_mapping[dept_unit_key]
                self.labeling_stats['dept_unit_match'] += 1
                return match_info['division'], 'dept_unit_match'
        
        # 2. ë¶€ì„œëª…ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš° í™•ì¸
        # ë¨¼ì € ê¸°ë³¸ ë¶€ì„œ ë§¤í•‘ í™•ì¸ (Unitì´ ì—†ëŠ” ê²½ìš°ë§Œ)
        if norm_dept in self.department_mapping:
            if not norm_unit:
                # Unitì´ ì—†ëŠ” ê²½ìš° - ê¸°ë³¸ ë¶€ì„œ ë§¤í•‘ ì‚¬ìš©
                division = self.department_mapping[norm_dept]
                self.labeling_stats['dept_only_match'] += 1
                return division, 'dept_only_match'
            else:
                # Unitì´ ìˆëŠ” ê²½ìš° - í–¥ìƒëœ ë§¤í•‘ì—ì„œ ì°¾ì•„ë³´ê¸°
                dept_unit_key = f"{norm_dept}|{norm_unit}"
                if dept_unit_key not in self.enhanced_mapping:
                    # Unitì´ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš° ë¯¸ë¶„ë¥˜ ì²˜ë¦¬
                    self.labeling_stats['unit_mismatch'] += 1
                    return 'ë¯¸ë¶„ë¥˜', 'unit_mismatch'
        
        # 3. í–¥ìƒëœ ë§¤í•‘ì—ì„œ ë¶€ì„œëª… ê¸°ë°˜ í™•ì¸
        dept_only_keys = [k for k in self.enhanced_mapping.keys() if k.startswith(f"{norm_dept}|")]
        
        if dept_only_keys:
            # Unitì´ ì—†ëŠ” ê²½ìš° - ë¶€ì„œëª…ë§Œìœ¼ë¡œ ë§¤í•‘
            if not norm_unit:
                dept_only_key = f"{norm_dept}|"
                if dept_only_key in self.enhanced_mapping:
                    match_info = self.enhanced_mapping[dept_only_key]
                    self.labeling_stats['dept_only_match'] += 1
                    return match_info['division'], 'dept_only_match'
            
            # Unitì´ ìˆì§€ë§Œ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš° - ë¯¸ë¶„ë¥˜
            else:
                # í•´ë‹¹ ë¶€ì„œì˜ ë‹¤ë¥¸ Unitë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
                dept_with_units = [k for k in dept_only_keys if k != f"{norm_dept}|"]
                if dept_with_units:
                    self.labeling_stats['unit_mismatch'] += 1
                    return 'ë¯¸ë¶„ë¥˜', 'unit_mismatch'
        
        # 4. ë¶€ì„œëª…ì´ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš°
        self.labeling_stats['dept_not_found'] += 1
        return 'ë¯¸ë¶„ë¥˜', 'dept_not_found'

    def generate_labeling_report(self, df):
        """ë¼ë²¨ë§ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        total_records = len(df)
        
        # ë¶€ë¬¸ ì»¬ëŸ¼ í™•ì¸ ('ë¶€ë¬¸' ë˜ëŠ” 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸')
        division_col = None
        if 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸' in df.columns:
            division_col = 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸'
        elif 'ë¶€ë¬¸' in df.columns:
            division_col = 'ë¶€ë¬¸'
        else:
            print("âŒ ë¶€ë¬¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        unclassified_count = (df[division_col] == 'ë¯¸ë¶„ë¥˜').sum()
        classified_count = total_records - unclassified_count
        
        print("\n" + "="*50)
        print("=== ë¶€ë¬¸ ë¼ë²¨ë§ ê²€ì¦ ë¦¬í¬íŠ¸ ===")
        print("="*50)
        print(f"- ì „ì²´ ë°ì´í„°: {total_records:,}ê±´")
        print(f"- ì •ìƒ ë§¤í•‘: {classified_count:,}ê±´ ({classified_count/total_records*100:.1f}%)")
        print(f"- ë¯¸ë¶„ë¥˜: {unclassified_count:,}ê±´ ({unclassified_count/total_records*100:.1f}%)")
        
        # ë¯¸ë¶„ë¥˜ ì¼€ì´ìŠ¤ ìƒìœ„ 10ê°œ ë¶€ì„œ
        if unclassified_count > 0:
            unclassified_df = df[df[division_col] == 'ë¯¸ë¶„ë¥˜']
            dept_unit_combinations = []
            
            for _, row in unclassified_df.iterrows():
                dept = row.get('í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…', '')
                unit = row.get('í”¼í‰ê°€ëŒ€ìƒ UNITëª…', '')
                if not self.is_empty_unit(unit):
                    combo = f"{dept} {unit}"
                else:
                    combo = dept
                dept_unit_combinations.append(combo)
            
            if dept_unit_combinations:
                unclassified_summary = pd.Series(dept_unit_combinations).value_counts().head(10)
                print(f"\n[ë¯¸ë¶„ë¥˜ ìƒìœ„ 10ê°œ ë¶€ì„œ/Unit ì¡°í•©]")
                for i, (combo, count) in enumerate(unclassified_summary.items(), 1):
                    print(f"{i}. {combo}: {count:,}ê±´")
        
        # ë§¤í•‘ ê·œì¹™ë³„ ì²˜ë¦¬ ê±´ìˆ˜
        print(f"\n[ë§¤í•‘ ê·œì¹™ë³„ ì²˜ë¦¬ ê±´ìˆ˜]")
        print(f"- ë¶€ì„œëª…+Unit ëª¨ë‘ ì¼ì¹˜: {self.labeling_stats['dept_unit_match']:,}ê±´")
        print(f"- ë¶€ì„œëª…ë§Œ ì¼ì¹˜(Unit ì—†ìŒ): {self.labeling_stats['dept_only_match']:,}ê±´")
        print(f"- ë¶€ì„œëª… ìˆì§€ë§Œ Unit ë§¤í•‘ ì—†ìŒ â†’ ë¯¸ë¶„ë¥˜: {self.labeling_stats['unit_mismatch']:,}ê±´")
        print(f"- ë¶€ì„œëª… ë§¤í•‘ ì—†ìŒ â†’ ë¯¸ë¶„ë¥˜: {self.labeling_stats['dept_not_found']:,}ê±´")
        print("="*50)
        
        return {
            'total': total_records,
            'classified': classified_count,
            'unclassified': unclassified_count,
            'classification_rate': classified_count/total_records*100,
            'stats': self.labeling_stats.copy()
        }

    def load_and_process_data(self, file_identifiers):
        """ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì‹œì‘...")
        self.load_department_standard_map()  # 1ï¸âƒ£ ë¨¼ì € í‘œì¤€í™” ë§¤í•‘ ë¡œë“œ
        self.load_department_mapping()       # 2ï¸âƒ£ í‘œì¤€í™”ë¥¼ ì ìš©í•œ ë¶€ë¬¸ ë§¤í•‘ ë¡œë“œ

        integrated_df = pd.DataFrame()
        for identifier in file_identifiers:
            normalized_identifier = unicodedata.normalize('NFKC', identifier)
            file_name_base = unicodedata.normalize('NFKC', 'ì„¤ë¬¸ì¡°ì‚¬ì§„í–‰í˜„í™©[VCRCRIC120S]_')
            file_name = f"{file_name_base}{normalized_identifier}.xlsx"

            actual_file_path = None
            for item in self.base_path.iterdir():
                if unicodedata.normalize('NFKC', item.name) == file_name:
                    actual_file_path = item
                    break

            if not actual_file_path:
                print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_name}")
                continue

            try:
                df = pd.read_excel(actual_file_path, sheet_name='ì§ì›ë³„ëŒ€ìƒë¬¸í•­ í˜„í™©')
                
                # Check if 'ì„¤ë¬¸ì‹œí–‰ì—°ë„' column exists in original data
                if 'ì„¤ë¬¸ì‹œí–‰ì—°ë„' in df.columns:
                    # Use original data as-is
                    pass
                else:
                    # Extract year from identifier (e.g., "2022_1" -> "2022")
                    year = identifier.split('_')[0] if '_' in identifier else identifier
                    df['ì„¤ë¬¸ì‹œí–‰ì—°ë„'] = year
                
                df['response_id'] = [f"{identifier}_{i+1}" for i in range(len(df))]
                integrated_df = pd.concat([integrated_df, df], ignore_index=True)
                print(f"  -> {actual_file_path.name} ({len(df)}í–‰ ë¡œë“œ)")
            except Exception as e:
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {actual_file_path.name}: {e}")

        if integrated_df.empty: 
            return pd.DataFrame(), {}
        
        processed_df = self._preprocess_data(integrated_df)
        self._print_processing_summary(processed_df, {})
        
        # ë¼ë²¨ë§ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        if 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸' in processed_df.columns or 'ë¶€ë¬¸' in processed_df.columns:
            if hasattr(self, 'labeling_stats'):  # í–¥ìƒëœ ë§¤í•‘ì´ ì‚¬ìš©ëœ ê²½ìš°ì—ë§Œ
                self.generate_labeling_report(processed_df)
        
        return processed_df, {}

    def _preprocess_data(self, df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        df = df.drop_duplicates(keep='first')

        def convert_score(score):
            if pd.isna(score): return None
            try:
                score_float = float(score)
                return ((score_float - 1) / 4) * 100 if score_float in [1, 2, 3, 4, 5] else None
            except (ValueError, TypeError): return None
        
        for q_col in self.question_columns:
            if q_col in df.columns: 
                df[q_col] = df[q_col].apply(convert_score)

        # Column renaming
        rename_map = {'UNITëª…': 'í‰ê°€_Unitëª…'}
        for col in df.columns:
            if 'ì–´ë–¤ ì—…ë¬´ë¥¼ í˜‘ë ¥í•˜ì—¬' in str(col):
                rename_map[col] = 'í˜‘ì—… ìœ í˜•'
            elif 'ë§Œì¡±ìŠ¤ëŸ¬ì› ê±°ë‚˜ ì•„ì‰¬ì› ë˜ ê²½í—˜' in str(col):
                rename_map[col] = 'í˜‘ì—… í›„ê¸°'

        df.rename(columns=rename_map, inplace=True)
        print("âœ… ì„œìˆ í˜• ì»¬ëŸ¼ ë° Unitëª… ë³€ê²½ ì™„ë£Œ")

        # Standardize department names
        cols_to_standardize = ['í‰ê°€_ë¶€ì„œëª…', 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…']
        if 'ë¶€ì„œëª…' in df.columns: 
            df.rename(columns={'ë¶€ì„œëª…': 'í‰ê°€_ë¶€ì„œëª…'}, inplace=True)

        if self.department_standard_map:
            for col_name in cols_to_standardize:
                if col_name in df.columns:
                    original_col_name = f"{col_name.replace(' ', '_')}_ì›ë³¸"
                    df.rename(columns={col_name: original_col_name}, inplace=True)
                    df[col_name] = df[original_col_name].map(self.department_standard_map).fillna(df[original_col_name])
                    print(f"âœ… '{col_name}' ì»¬ëŸ¼ í‘œì¤€í™” ì ìš© ì™„ë£Œ")

        # Calculate scores
        available_q_cols = [col for col in self.question_columns if col in df.columns]
        if available_q_cols:
            df['ê²°ì¸¡ê°’'] = df[available_q_cols].isnull().any(axis=1).apply(lambda x: 'Y' if x else 'N')
            df['ì¢…í•©ì ìˆ˜'] = df[available_q_cols].mean(axis=1, skipna=True).round(2)
        
        def check_extreme_value(row):
            return 'ê·¹ë‹¨ê°’' if pd.notna(row.get('ì¢…í•©ì ìˆ˜')) and row['ì¢…í•©ì ìˆ˜'] == 0 else 'ì •ìƒ'
        df['ê·¹ë‹¨ê°’'] = df.apply(check_extreme_value, axis=1)

        # Enhanced department to division mapping
        if 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…' in df.columns:
            print("ğŸ¢ í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸ ë§¤í•‘ ì‹œì‘ (í–¥ìƒëœ ë§¤í•‘ ì‚¬ìš©)...")
            
            # í†µê³„ ì´ˆê¸°í™”
            self.labeling_stats = {
                'dept_unit_match': 0,
                'dept_only_match': 0, 
                'dept_not_found': 0,
                'unit_mismatch': 0
            }
            
            # í–¥ìƒëœ ë¼ë²¨ë§ ì ìš©
            dept_col = 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…'
            unit_col = 'í”¼í‰ê°€ëŒ€ìƒ UNITëª…' if 'í”¼í‰ê°€ëŒ€ìƒ UNITëª…' in df.columns else None
            
            divisions = []
            match_types = []
            
            for _, row in df.iterrows():
                dept_name = row[dept_col]
                unit_name = row[unit_col] if unit_col else None
                
                division, match_type = self.enhanced_department_labeling(dept_name, unit_name)
                divisions.append(division)
                match_types.append(match_type)
            
            df['ë¶€ë¬¸'] = divisions
            print("ğŸ¢ í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸ ë§¤í•‘ ì™„ë£Œ (í–¥ìƒëœ ë§¤í•‘)")

        if 'í‰ê°€_ë¶€ì„œëª…' in df.columns:
            print("ğŸ¢ í‰ê°€ì ë¶€ë¬¸ ë§¤í•‘ ì‹œì‘...")
            # í‰ê°€ìë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            dept_col = 'í‰ê°€_ë¶€ì„œëª…'
            unit_col = 'í‰ê°€_Unitëª…' if 'í‰ê°€_Unitëª…' in df.columns else None
            
            # ë³„ë„ í†µê³„ë¥¼ ìœ„í•´ ì„ì‹œ ì €ì¥
            temp_stats = self.labeling_stats.copy()
            self.labeling_stats = {
                'dept_unit_match': 0,
                'dept_only_match': 0, 
                'dept_not_found': 0,
                'unit_mismatch': 0
            }
            
            divisions = []
            for _, row in df.iterrows():
                dept_name = row[dept_col]
                unit_name = row[unit_col] if unit_col else None
                
                division, _ = self.enhanced_department_labeling(dept_name, unit_name)
                divisions.append(division)
            
            df['í‰ê°€_ë¶€ë¬¸'] = divisions
            
            # ì›ë˜ í†µê³„ ë³µì› (í”¼í‰ê°€ëŒ€ìƒ ê¸°ì¤€ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±)
            self.labeling_stats = temp_stats
            print("ğŸ¢ í‰ê°€ì ë¶€ë¬¸ ë§¤í•‘ ì™„ë£Œ")

        return df

    def _print_processing_summary(self, df, processing_stats):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60 + "\nğŸ“Š ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n" + "="*60)
        print(f"ğŸ“‹ ì´ ì‘ë‹µ ìˆ˜: {len(df):,}ê°œ")
        if 'ê²°ì¸¡ê°’' in df.columns:
            print(f"â“ ê²°ì¸¡ê°’ í¬í•¨ ì‘ë‹µ: {(df['ê²°ì¸¡ê°’'] == 'Y').sum():,}ê°œ")
        if 'ê·¹ë‹¨ê°’' in df.columns:
            print(f"âš ï¸ ê·¹ë‹¨ê°’(ì¢…í•©ì ìˆ˜ 0ì ) ì‘ë‹µ: {(df['ê·¹ë‹¨ê°’'] == 'ê·¹ë‹¨ê°’').sum():,}ê°œ")
        if 'ì¢…í•©ì ìˆ˜' in df.columns and df['ì¢…í•©ì ìˆ˜'].notna().any():
            print(f"ğŸ“Š ì „ì²´ í‰ê·  ì ìˆ˜ (0-100ì  ì²™ë„): {df['ì¢…í•©ì ìˆ˜'].mean():.2f}ì ")
        print("="*60)

    def prepare_final_output(self, df):
        """ìµœì¢… ì¶œë ¥ì„ ìœ„í•œ ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬"""
        desired_columns = [
            'response_id', 'ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€_ë¶€ì„œëª…', 'í‰ê°€_ë¶€ì„œëª…_ì›ë³¸', 'í‰ê°€_Unitëª…', 'í‰ê°€_ë¶€ë¬¸',
            'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…', 'í”¼í‰ê°€ëŒ€ìƒ_ë¶€ì„œëª…_ì›ë³¸', 'í”¼í‰ê°€ëŒ€ìƒ UNITëª…', 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸',
            'â—‹â—‹ì€ íƒ€ ë¶€ì„œì˜ ì…ì¥ì„ ì¡´ì¤‘í•˜ê³  ë°°ë ¤í•˜ì—¬ í˜‘ë ¥í•´ì£¼ë©°. í˜‘ì—… ê´€ë ¨ ì˜ê²¬ì„ ê²½ì²­í•´ì¤€ë‹¤.',
            'â—‹â—‹ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ì •ë³´ì— ëŒ€í•´ ê³µìœ ê°€ ì˜ ì´ë£¨ì–´ì§„ë‹¤.',
            'â—‹â—‹ì€ ì—…ë¬´ì— ëŒ€í•œ ëª…í™•í•œ ë‹´ë‹¹ìê°€ ìˆê³  ì—…ë¬´ë¥¼ ì¼ê´€ì„±ìˆê²Œ ì²˜ë¦¬í•´ì¤€ë‹¤.',
            'â—‹â—‹ì€ ì´ì „ë³´ë‹¤ ì—…ë¬´ í˜‘ë ¥ì— ëŒ€í•œ íƒœë„ë‚˜ ì˜ì§€ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.',
            'ì „ë°˜ì ìœ¼ë¡œ â—‹â—‹ê³¼ì˜ í˜‘ì—…ì— ëŒ€í•´ ë§Œì¡±í•œë‹¤.',
            'ì¢…í•©ì ìˆ˜', 'ê·¹ë‹¨ê°’', 'ê²°ì¸¡ê°’', 'í˜‘ì—… ìœ í˜•', 'í˜‘ì—… í›„ê¸°'
        ]
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘ (ê¸°ì¡´ ì»¬ëŸ¼ëª… â†’ ì›í•˜ëŠ” ì»¬ëŸ¼ëª…)
        column_mapping = {
            'ë¶€ë¬¸': 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸'
        }
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        df_final = df.copy()
        for old_name, new_name in column_mapping.items():
            if old_name in df_final.columns and new_name != old_name:
                df_final.rename(columns={old_name: new_name}, inplace=True)
                # ì›í•˜ëŠ” ìˆœì„œë¡œ ì»¬ëŸ¼ ì¬ì •ë ¬ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
        available_columns = [col for col in desired_columns if col in df_final.columns]
        df_final = df_final[available_columns]
        
        print(f"âœ… ìµœì¢… ì¶œë ¥ í˜•ì‹ ì •ë¦¬ ì™„ë£Œ: {len(available_columns)}ê°œ ì»¬ëŸ¼")
        return df_final


def main_local_analysis(base_path: str, project_id: str = None):
    """ë©”ì¸ ë¡œì»¬ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸš€ ë¡œì»¬ í™˜ê²½ì—ì„œ í˜‘ì—… í‰ê°€ ë¶„ì„ ì‹œì‘")
    
    # íŒŒì¼ ì¸ì‹
    raw_data_path = Path(base_path)
    file_prefix = "ì„¤ë¬¸ì¡°ì‚¬ì§„í–‰í˜„í™©[VCRCRIC120S]_"
    file_suffix = ".xlsx"
    file_identifiers = []
    
    if raw_data_path.exists():
        normalized_prefix = unicodedata.normalize('NFKC', file_prefix)
        for item in raw_data_path.iterdir():
            if item.is_file():
                normalized_filename = unicodedata.normalize('NFKC', item.name)
                if normalized_filename.startswith(normalized_prefix) and normalized_filename.endswith(file_suffix):
                    identifier = normalized_filename.replace(normalized_prefix, "").replace(file_suffix, "")
                    file_identifiers.append(identifier)
        file_identifiers.sort()

    if not file_identifiers:
        print(f"\nâŒ ë¶„ì„í•  ì„¤ë¬¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    print(f"\nâœ… {len(file_identifiers)}ê°œì˜ ì„¤ë¬¸ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {file_identifiers}")

    # ë§¤í•‘ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    standard_map_path = raw_data_path / "ë¶€ì„œëª…_í‘œì¤€í™”_ë§¤í•‘.xlsx"
    mapping_file_path = raw_data_path / "ë¶€ì„œ_ë¶€ë¬¸_ë§¤í•‘.xlsx"

    
    # ë°ì´í„° ë¶„ì„ê¸° ì‹¤í–‰
    analyzer = LocalGoogleSheetsAnalyzer(
        base_path, 
        mapping_file_path=str(mapping_file_path) if mapping_file_path.exists() else None,
        standard_map_path=str(standard_map_path) if standard_map_path.exists() else None
    )
    processed_df, _ = analyzer.load_and_process_data(file_identifiers)
    
    if processed_df.empty:
        print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # AI ë¶„ì„ (ì˜µì…˜)
    if project_id:
        ai_analyzer = LocalAIAnalyzer(project_id)
        processed_df = ai_analyzer.analyze_dataframe(processed_df)

    # ìµœì¢… ì¶œë ¥ í˜•ì‹ ì •ë¦¬
    analyzer = LocalGoogleSheetsAnalyzer(
        base_path, 
        mapping_file_path=str(mapping_file_path) if mapping_file_path.exists() else None,
        standard_map_path=str(standard_map_path) if standard_map_path.exists() else None
    )
    final_df = analyzer.prepare_final_output(processed_df)
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"1. data_processor_ê²°ê³¼_{timestamp}.xlsx"
    output_path = Path(base_path) / output_filename
    final_df.to_excel(output_path, index=False)
    print(f"âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

    return final_df


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    BASE_PATH = "./rawdata"  # rawdata í´ë”ì—ì„œ íŒŒì¼ ê²€ìƒ‰
    PROJECT_ID = None  # Google Cloud í”„ë¡œì íŠ¸ ID (ì˜µì…˜)
    
    result_df = main_local_analysis(BASE_PATH, PROJECT_ID)
    if result_df is not None:
        print("\nğŸ‰ ë¡œì»¬ ë¶„ì„ ì™„ë£Œ!")
        print(f"ì´ {len(result_df)}ê°œì˜ ë ˆì½”ë“œê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")