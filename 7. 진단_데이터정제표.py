#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° ì •ì œ ê³¼ì • ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸

ì›ë³¸ Excel íŒŒì¼ê³¼ ì •ì œ í›„ ë°ì´í„°ì˜ ì°¨ì´ë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

ì‘ì„±ì¼: 2025-01-15
"""

import pandas as pd
from pathlib import Path


def get_latest_text_processor_file():
    """
    rawdata í´ë”ì—ì„œ ê°€ì¥ ìµœì‹ ì˜ text_processor_ê²°ê³¼ íŒŒì¼ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        str: ê°€ì¥ ìµœì‹  íŒŒì¼ì˜ ê²½ë¡œ
    """
    rawdata_path = Path("rawdata")
    pattern = "2. text_processor_ê²°ê³¼_*.xlsx"

    # _partial.xlsx íŒŒì¼ì€ ì œì™¸í•˜ê³  ê²€ìƒ‰
    files = [f for f in rawdata_path.glob(pattern) if not f.name.endswith('_partial.xlsx')]

    if not files:
        print(f"âš ï¸  '{pattern}' íŒ¨í„´ì˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return "rawdata/2. text_processor_ê²°ê³¼_20251013_093925.xlsx"  # ê¸°ë³¸ê°’

    # íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ì¶œí•˜ì—¬ ìµœì‹  íŒŒì¼ ì„ íƒ
    if len(files) > 1:
        latest_file = max(files, key=lambda f: f.stat().st_mtime)
        print(f"ğŸ“ ìµœì‹  ë°ì´í„° íŒŒì¼ ìë™ ì„ íƒ: {latest_file.name}")
        return str(latest_file)
    else:
        return str(files[0])


def extract_period_from_response_id(response_id):
    """
    response_idì—ì„œ ì—°ë„ì™€ ë°˜ê¸°ë¥¼ ì¶”ì¶œí•˜ì—¬ ê¸°ê°„ í‘œì‹œ ìƒì„±

    Args:
        response_id: response_id ê°’ (ì˜ˆ: '2025_1_123', '2024_1_456')

    Returns:
        str: ê¸°ê°„ í‘œì‹œ (ì˜ˆ: '2025ë…„ ìƒë°˜ê¸°', '2024ë…„')
    """
    try:
        parts = str(response_id).split('_')
        if len(parts) >= 2:
            year = parts[0]
            period = parts[1]

            # 2025ë…„ë§Œ ìƒë°˜ê¸°/í•˜ë°˜ê¸°ë¡œ êµ¬ë¶„
            if year == "2025":
                period_name = "ìƒë°˜ê¸°" if period == "1" else "í•˜ë°˜ê¸°"
                return f"{year}ë…„ {period_name}"
            else:
                # ë‚˜ë¨¸ì§€ ì—°ë„ëŠ” ì—°ë„ë§Œ í‘œì‹œ
                return f"{year}ë…„"
        return str(response_id)
    except:
        return str(response_id)


def analyze_data_cleaning_steps(split_mode=False):
    """
    ë°ì´í„° ì •ì œ ë‹¨ê³„ë³„ ë¶„ì„

    Args:
        split_mode (bool): Trueì´ë©´ 2025ë…„ì„ ìƒí•˜ë°˜ê¸°ë¡œ ë¶„ë¦¬, Falseì´ë©´ ì—°ë„ë³„ í†µí•©
    """

    mode_text = "2025ë…„ ìƒí•˜ë°˜ê¸° ë¶„ë¦¬" if split_mode else "ì—°ë„ë³„ í†µí•©"
    print("=" * 80)
    print(f"ğŸ“Š ë°ì´í„° ì •ì œ ê³¼ì • ì§„ë‹¨ ({mode_text})")
    print("=" * 80)
    print()

    # ì›ë³¸ íŒŒì¼ ë¡œë“œ
    input_file = get_latest_text_processor_file()
    print(f"ğŸ“ íŒŒì¼ ë¡œë“œ: {input_file}\n")

    df_original = pd.read_excel(input_file)

    # ì»¬ëŸ¼ëª… ì •ì˜ (ì›ë³¸ê³¼ ë™ì¼)
    EXCEL_COLUMNS = [
        'response_id', 'ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€_ë¶€ì„œëª…', 'í‰ê°€_ë¶€ì„œëª…_ì›ë³¸', 'í‰ê°€_Unitëª…', 'í‰ê°€_ë¶€ë¬¸',
        'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…', 'í”¼í‰ê°€ëŒ€ìƒ_ë¶€ì„œëª…_ì›ë³¸', 'í”¼í‰ê°€ëŒ€ìƒ UNITëª…', 'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸',
        'â—‹â—‹ì€ íƒ€ ë¶€ì„œì˜ ì…ì¥ì„ ì¡´ì¤‘í•˜ê³  ë°°ë ¤í•˜ì—¬ í˜‘ë ¥í•´ì£¼ë©°. í˜‘ì—… ê´€ë ¨ ì˜ê²¬ì„ ê²½ì²­í•´ì¤€ë‹¤.',
        'â—‹â—‹ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ì •ë³´ì— ëŒ€í•´ ê³µìœ ê°€ ì˜ ì´ë£¨ì–´ì§„ë‹¤.',
        'â—‹â—‹ì€ ì—…ë¬´ì— ëŒ€í•œ ëª…í™•í•œ ë‹´ë‹¹ìê°€ ìˆê³  ì—…ë¬´ë¥¼ ì¼ê´€ì„±ìˆê²Œ ì²˜ë¦¬í•´ì¤€ë‹¤.',
        'â—‹â—‹ì€ ì´ì „ë³´ë‹¤ ì—…ë¬´ í˜‘ë ¥ì— ëŒ€í•œ íƒœë„ë‚˜ ì˜ì§€ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.',
        'ì „ë°˜ì ìœ¼ë¡œ â—‹â—‹ê³¼ì˜ í˜‘ì—…ì— ëŒ€í•´ ë§Œì¡±í•œë‹¤.',
        'ì¢…í•©ì ìˆ˜', 'ê·¹ë‹¨ê°’', 'ê²°ì¸¡ê°’', 'í˜‘ì—… ìœ í˜•', 'í˜‘ì—… í›„ê¸°', 'ì •ì œëœ_í…ìŠ¤íŠ¸',
        'ë¹„ì‹ë³„_ì²˜ë¦¬', 'ê°ì •_ë¶„ë¥˜', 'ê°ì •_ê°•ë„_ì ìˆ˜', 'í•µì‹¬_í‚¤ì›Œë“œ', 'ì˜ë£Œ_ë§¥ë½', 'ì‹ ë¢°ë„_ì ìˆ˜'
    ]

    df_original.columns = EXCEL_COLUMNS

    # ì»¬ëŸ¼ëª… ë§¤í•‘
    column_mapping = {
        'ì„¤ë¬¸ì‹œí–‰ì—°ë„': 'ì„¤ë¬¸ì‹œí–‰ì—°ë„',
        'í‰ê°€_ë¶€ì„œëª…': 'í‰ê°€ë¶€ì„œ',
        'í‰ê°€_ë¶€ë¬¸': 'í‰ê°€ë¶€ë¬¸',
        'í”¼í‰ê°€ëŒ€ìƒ ë¶€ì„œëª…': 'í”¼í‰ê°€ë¶€ì„œ',
        'í”¼í‰ê°€ëŒ€ìƒ ë¶€ë¬¸': 'í”¼í‰ê°€ë¶€ë¬¸',
        'í”¼í‰ê°€ëŒ€ìƒ UNITëª…': 'í”¼í‰ê°€Unit',
        'â—‹â—‹ì€ íƒ€ ë¶€ì„œì˜ ì…ì¥ì„ ì¡´ì¤‘í•˜ê³  ë°°ë ¤í•˜ì—¬ í˜‘ë ¥í•´ì£¼ë©°. í˜‘ì—… ê´€ë ¨ ì˜ê²¬ì„ ê²½ì²­í•´ì¤€ë‹¤.': 'ì¡´ì¤‘ë°°ë ¤',
        'â—‹â—‹ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ì •ë³´ì— ëŒ€í•´ ê³µìœ ê°€ ì˜ ì´ë£¨ì–´ì§„ë‹¤.': 'ì •ë³´ê³µìœ ',
        'â—‹â—‹ì€ ì—…ë¬´ì— ëŒ€í•œ ëª…í™•í•œ ë‹´ë‹¹ìê°€ ìˆê³  ì—…ë¬´ë¥¼ ì¼ê´€ì„±ìˆê²Œ ì²˜ë¦¬í•´ì¤€ë‹¤.': 'ëª…í™•ì²˜ë¦¬',
        'â—‹â—‹ì€ ì´ì „ë³´ë‹¤ ì—…ë¬´ í˜‘ë ¥ì— ëŒ€í•œ íƒœë„ë‚˜ ì˜ì§€ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.': 'íƒœë„ê°œì„ ',
        'ì „ë°˜ì ìœ¼ë¡œ â—‹â—‹ê³¼ì˜ í˜‘ì—…ì— ëŒ€í•´ ë§Œì¡±í•œë‹¤.': 'ì „ë°˜ë§Œì¡±',
        'ì¢…í•©ì ìˆ˜': 'ì¢…í•©ì ìˆ˜',
        'í˜‘ì—… í›„ê¸°': 'í˜‘ì—…í›„ê¸°'
    }

    df_original = df_original.rename(columns=column_mapping)
    df_original['ì„¤ë¬¸ì‹œí–‰ì—°ë„'] = df_original['ì„¤ë¬¸ì‹œí–‰ì—°ë„'].astype(str)

    # ê¸°ê°„_í‘œì‹œ ì»¬ëŸ¼ ì¶”ê°€
    if 'response_id' in df_original.columns:
        df_original['ê¸°ê°„_í‘œì‹œ'] = df_original['response_id'].apply(extract_period_from_response_id)
    else:
        df_original['ê¸°ê°„_í‘œì‹œ'] = df_original['ì„¤ë¬¸ì‹œí–‰ì—°ë„'] + 'ë…„'

    # split_modeì— ë”°ë¼ ì§‘ê³„ ê¸°ì¤€ ê²°ì •
    group_column = 'ê¸°ê°„_í‘œì‹œ' if split_mode else 'ì„¤ë¬¸ì‹œí–‰ì—°ë„'

    print("ğŸ” STEP 0: ì›ë³¸ ë°ì´í„°")
    print("-" * 80)
    print(f"ì´ í–‰ìˆ˜: {len(df_original):,}í–‰\n")

    year_counts_original = df_original[group_column].value_counts().sort_index()
    period_label = "ê¸°ê°„ë³„" if split_mode else "ì—°ë„ë³„"
    print(f"{period_label} í–‰ìˆ˜:")
    for period, count in year_counts_original.items():
        print(f"  {period}: {count:,}í–‰")
    print()

    # STEP 1: ë¶€ë¬¸ ê¸°ì¤€ ì œì™¸
    print("ğŸ” STEP 1: ë¶€ë¬¸ ê¸°ì¤€ í•„í„°ë§ (ë¯¸ë¶„ë¥˜, ìœ¤ë¦¬ê²½ì˜ì‹¤ ì œì™¸)")
    print("-" * 80)

    EXCLUDE_DEPARTMENTS = ['ë¯¸ë¶„ë¥˜', 'ìœ¤ë¦¬ê²½ì˜ì‹¤']
    df_step1 = df_original.copy()

    for exclude_dept in EXCLUDE_DEPARTMENTS:
        before = len(df_step1)
        condition = (df_step1['í‰ê°€ë¶€ë¬¸'] != exclude_dept) & (df_step1['í”¼í‰ê°€ë¶€ë¬¸'] != exclude_dept)
        df_step1 = df_step1[condition]
        removed = before - len(df_step1)
        if removed > 0:
            print(f"  '{exclude_dept}' ì œì™¸: {removed:,}í–‰ ì œê±°")

            # ê¸°ê°„ë³„ë¡œ ì–´ë–»ê²Œ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
            removed_data = df_original[~df_original.index.isin(df_step1.index)]
            removed_by_period = removed_data[
                (removed_data['í‰ê°€ë¶€ë¬¸'] == exclude_dept) |
                (removed_data['í”¼í‰ê°€ë¶€ë¬¸'] == exclude_dept)
            ][group_column].value_counts().sort_index()

            if len(removed_by_period) > 0:
                for period, count in removed_by_period.items():
                    print(f"    - {period}: {count:,}í–‰")

    print(f"\nì´ ë‚¨ì€ í–‰ìˆ˜: {len(df_step1):,}í–‰")

    year_counts_step1 = df_step1[group_column].value_counts().sort_index()
    print(f"\n{period_label} í–‰ìˆ˜:")
    for period, count in year_counts_step1.items():
        original_count = year_counts_original.get(period, 0)
        diff = original_count - count
        print(f"  {period}: {count:,}í–‰ (ì›ë³¸ ëŒ€ë¹„ -{diff:,}í–‰)")
    print()

    # STEP 2: ë¶€ì„œ ê¸°ì¤€ ì œì™¸
    print("ğŸ” STEP 2: ë¶€ì„œ ê¸°ì¤€ í•„í„°ë§ (ë‚´ë¶„ë¹„ì™¸ê³¼ ì œì™¸)")
    print("-" * 80)

    EXCLUDE_TEAMS = ['ë‚´ë¶„ë¹„ì™¸ê³¼']
    df_step2 = df_step1.copy()

    for exclude_team in EXCLUDE_TEAMS:
        before = len(df_step2)
        condition = (df_step2['í‰ê°€ë¶€ì„œ'] != exclude_team) & (df_step2['í”¼í‰ê°€ë¶€ì„œ'] != exclude_team)
        df_step2 = df_step2[condition]
        removed = before - len(df_step2)
        if removed > 0:
            print(f"  '{exclude_team}' ì œì™¸: {removed:,}í–‰ ì œê±°")

            # ê¸°ê°„ë³„ë¡œ ì–´ë–»ê²Œ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
            removed_data = df_step1[~df_step1.index.isin(df_step2.index)]
            removed_by_period = removed_data[
                (removed_data['í‰ê°€ë¶€ì„œ'] == exclude_team) |
                (removed_data['í”¼í‰ê°€ë¶€ì„œ'] == exclude_team)
            ][group_column].value_counts().sort_index()

            if len(removed_by_period) > 0:
                for period, count in removed_by_period.items():
                    print(f"    - {period}: {count:,}í–‰")

    print(f"\nì´ ë‚¨ì€ í–‰ìˆ˜: {len(df_step2):,}í–‰")

    year_counts_step2 = df_step2[group_column].value_counts().sort_index()
    print(f"\n{period_label} í–‰ìˆ˜:")
    for period, count in year_counts_step2.items():
        original_count = year_counts_original.get(period, 0)
        diff = original_count - count
        print(f"  {period}: {count:,}í–‰ (ì›ë³¸ ëŒ€ë¹„ -{diff:,}í–‰)")
    print()

    # STEP 3: ì¢…í•©ì ìˆ˜ ê²°ì¸¡ê°’ ì œê±°
    print("ğŸ” STEP 3: ì¢…í•©ì ìˆ˜ ê²°ì¸¡ê°’ ì œê±°")
    print("-" * 80)

    df_step3 = df_step2.copy()
    df_step3['ì¢…í•©ì ìˆ˜'] = pd.to_numeric(df_step3['ì¢…í•©ì ìˆ˜'], errors='coerce')

    before = len(df_step3)
    df_step3 = df_step3.dropna(subset=['ì¢…í•©ì ìˆ˜'])
    removed = before - len(df_step3)

    print(f"  ì¢…í•©ì ìˆ˜ ê²°ì¸¡ê°’: {removed:,}í–‰ ì œê±°")

    # ê¸°ê°„ë³„ë¡œ ì–´ë–»ê²Œ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
    removed_data = df_step2[~df_step2.index.isin(df_step3.index)]
    removed_by_period = removed_data[group_column].value_counts().sort_index()

    if len(removed_by_period) > 0:
        for period, count in removed_by_period.items():
            print(f"    - {period}: {count:,}í–‰")

    print(f"\nì´ ë‚¨ì€ í–‰ìˆ˜: {len(df_step3):,}í–‰")

    year_counts_step3 = df_step3[group_column].value_counts().sort_index()
    print(f"\n{period_label} í–‰ìˆ˜:")
    for period, count in year_counts_step3.items():
        original_count = year_counts_original.get(period, 0)
        diff = original_count - count
        print(f"  {period}: {count:,}í–‰ (ì›ë³¸ ëŒ€ë¹„ -{diff:,}í–‰)")
    print()

    # ìµœì¢… ìš”ì•½
    print("=" * 80)
    print("ğŸ“‹ ìµœì¢… ìš”ì•½")
    print("=" * 80)
    print()

    period_column_name = 'ê¸°ê°„' if split_mode else 'ì—°ë„'
    summary_df = pd.DataFrame({
        period_column_name: sorted(year_counts_original.index),
        'ì›ë³¸': [year_counts_original.get(period, 0) for period in sorted(year_counts_original.index)],
        'STEP1_ë¶€ë¬¸í•„í„°': [year_counts_step1.get(period, 0) for period in sorted(year_counts_original.index)],
        'STEP2_ë¶€ì„œí•„í„°': [year_counts_step2.get(period, 0) for period in sorted(year_counts_original.index)],
        'STEP3_ì¢…í•©ì ìˆ˜': [year_counts_step3.get(period, 0) for period in sorted(year_counts_original.index)]
    })

    summary_df['ì´_ì œê±°'] = summary_df['ì›ë³¸'] - summary_df['STEP3_ì¢…í•©ì ìˆ˜']
    summary_df['ì œê±°ìœ¨(%)'] = (summary_df['ì´_ì œê±°'] / summary_df['ì›ë³¸'] * 100).round(2)

    print(summary_df.to_string(index=False))
    print()

    # ìƒì„¸ í•„í„°ë§ ì¡°ê±´ ì €ì¥
    print("ğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ Excelë¡œ ì €ì¥í•©ë‹ˆë‹¤...")

    mode_suffix = '_ë°˜ê¸°ë³„' if split_mode else '_ì—°ë„ë³„'
    output_file = f'ì§„ë‹¨_ë°ì´í„°ì •ì œí‘œ{mode_suffix}.xlsx'

    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ìš”ì•½
        summary_df.to_excel(writer, sheet_name='ìš”ì•½', index=False)

        # ë¶€ë¬¸ ì œì™¸ ìƒì„¸
        excluded_divisions_cols = ['ê¸°ê°„_í‘œì‹œ', 'ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ'] if split_mode else ['ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ']
        excluded_divisions = df_original[
            (df_original['í‰ê°€ë¶€ë¬¸'].isin(EXCLUDE_DEPARTMENTS)) |
            (df_original['í”¼í‰ê°€ë¶€ë¬¸'].isin(EXCLUDE_DEPARTMENTS))
        ][[col for col in excluded_divisions_cols if col in df_original.columns]].copy()
        if len(excluded_divisions) > 0:
            excluded_divisions.to_excel(writer, sheet_name='ì œì™¸_ë¶€ë¬¸_ìƒì„¸', index=False)

        # ë¶€ì„œ ì œì™¸ ìƒì„¸
        excluded_teams_cols = ['ê¸°ê°„_í‘œì‹œ', 'ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ'] if split_mode else ['ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ']
        excluded_teams = df_step1[
            (df_step1['í‰ê°€ë¶€ì„œ'].isin(EXCLUDE_TEAMS)) |
            (df_step1['í”¼í‰ê°€ë¶€ì„œ'].isin(EXCLUDE_TEAMS))
        ][[col for col in excluded_teams_cols if col in df_step1.columns]].copy()
        if len(excluded_teams) > 0:
            excluded_teams.to_excel(writer, sheet_name='ì œì™¸_ë¶€ì„œ_ìƒì„¸', index=False)

        # ì¢…í•©ì ìˆ˜ ê²°ì¸¡ê°’ ìƒì„¸
        missing_scores_cols = ['ê¸°ê°„_í‘œì‹œ', 'ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ', 'ì¢…í•©ì ìˆ˜'] if split_mode else ['ì„¤ë¬¸ì‹œí–‰ì—°ë„', 'í‰ê°€ë¶€ë¬¸', 'í”¼í‰ê°€ë¶€ë¬¸', 'í‰ê°€ë¶€ì„œ', 'í”¼í‰ê°€ë¶€ì„œ', 'ì¢…í•©ì ìˆ˜']
        missing_scores = df_step2[pd.isna(pd.to_numeric(df_step2['ì¢…í•©ì ìˆ˜'], errors='coerce'))][
            [col for col in missing_scores_cols if col in df_step2.columns]
        ].copy()
        if len(missing_scores) > 0:
            missing_scores.to_excel(writer, sheet_name='ì¢…í•©ì ìˆ˜_ê²°ì¸¡_ìƒì„¸', index=False)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_file}")
    print()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ë°ì´í„° ì •ì œ ê³¼ì • ì§„ë‹¨')
    parser.add_argument('--split', action='store_true', help='2025ë…„ì„ ìƒí•˜ë°˜ê¸°ë¡œ ë¶„ë¦¬')

    args = parser.parse_args()

    analyze_data_cleaning_steps(split_mode=args.split)
